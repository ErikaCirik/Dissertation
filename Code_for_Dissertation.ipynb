{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9faf421-67f7-456e-864e-e53f5043ee6e",
   "metadata": {},
   "source": [
    "# Code for the MA981: Dissertation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0c8b3f-1fbd-47b8-9859-03fe49434dd9",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5cf2dc-aca9-4c21-bc38-477ac2367b60",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275f304-d4d9-4d73-b4f6-02a2d0649591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedShuffleSplit, KFold, StratifiedKFold,TimeSeriesSplit\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer,accuracy_score,precision_score, recall_score, matthews_corrcoef, auc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, KFold\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK,Trials, space_eval\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn import ensemble\n",
    "from functools import partial\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "import smote_variants as sv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f3472-c4b3-4ab9-bf2a-cd46bbc16da5",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ae741-38ec-46c1-99e4-f0b745b6c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = pd.read_excel('Training_dataset_Original.xlsx', engine='openpyxl')\n",
    "base_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89de4da-0315-423b-bcf0-46e53d01f1d0",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba62d9-802c-4400-ab09-1b7f0c8430f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing nan with empty string using replace() function \n",
    "nomiss_data = base_data.replace('missing', np.nan)\n",
    "nomiss_data=nomiss_data.replace('na', np.nan)\n",
    "nomiss_data=nomiss_data.replace(' ', np.nan)\n",
    "nomiss_data=nomiss_data.replace('', np.nan)\n",
    "# checking the nan values\n",
    "nomiss_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1629a8-af4f-4810-8aa0-02585e381eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for categorical variables\n",
    "print(nomiss_data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6698fd-3eb7-44e3-bf57-e54f25a52d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ordinal values to numbers\n",
    "density_map = {\n",
    "    'C' : 0,\n",
    "    'L' : 1\n",
    "}\n",
    "nomiss_data['mvar47'] = nomiss_data['mvar47'].map(density_map)\n",
    "nomiss_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c988f73c-5fb7-4f26-b2a4-bed4e2d52dd1",
   "metadata": {},
   "source": [
    "### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee0119-d308-4258-982c-5c415f424617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of data\n",
    "print(\"The data size is: {} \".format(nomiss_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d73b05-f1a6-4cc8-bccf-884c07f6a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomiss_data.drop_duplicates(inplace=True)\n",
    "#size of data after deleting duplicates\n",
    "print(\"The data size is: {} \".format(nomiss_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895fab03-1c36-479e-834c-81b8d8fdb1f5",
   "metadata": {},
   "source": [
    "### Some tidying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b272513-6ef8-445d-9098-6457bb0e3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['application_key']\n",
    "tidy_data = nomiss_data.drop(list,axis = 1 )\n",
    "tidy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ecd00-adcb-4dd2-be9b-bf8484a61feb",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5fd042-2703-4e11-b161-1788b4b34248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation map\n",
    "%matplotlib inline\n",
    "f,ax = plt.subplots(figsize=(25,25))\n",
    "plt.title('Correlation Heatmap of the Dataset')\n",
    "\n",
    "corr_df =  tidy_data.corr(method='pearson') \n",
    "corr_bottom = corr_df.where(np.tril(np.ones(corr_df.shape), k=-1).astype(bool))\n",
    "\n",
    "hmap=sns.heatmap(corr_bottom, annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
    "hmap.figure.savefig(\"Correlation_Heatmap_Lower_Triangle_with_Seaborn.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550602c-94bd-425b-beea-c3faecfbb8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index of feature columns with correlation greater than 0.9\n",
    "to_drop_plus = [column for column in corr_bottom.columns if any(corr_bottom[column] > 0.9)]\n",
    "print(to_drop_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f892ce0-e8db-481f-a1c2-0f7a5856c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Marked Features\n",
    "nocorr_data = tidy_data.drop(to_drop_plus, axis='columns')\n",
    "print(nocorr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd69c610-3410-4253-9e91-53a0c95f3e1a",
   "metadata": {},
   "source": [
    "### Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9914f5-83f3-4eea-a168-25d7c80a9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "print('Dataset columns with missing values:\\n', nocorr_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf339ac-2d5e-46ce-a79c-c7f5c6505843",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(random_state=42)\n",
    "cat_feat = nocorr_data[['mvar47', 'default_ind']]\n",
    "int_feat = nocorr_data.drop(['mvar47', 'default_ind'], axis=1)\n",
    "imputed = imputer.fit_transform(int_feat)\n",
    "int_imputed = pd.DataFrame(imputed, columns=int_feat.columns)\n",
    "imputted_data = pd.merge(int_imputed, cat_feat, left_index=True, right_index=True)\n",
    "imputted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65366b5-a6c6-43f2-81c9-c6fb8c0dc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null value\n",
    "imputted_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733bf51-1cc5-4ef5-9027-25142624e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking na value\n",
    "imputted_data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76361b-f0e6-4bf1-a867-94eb0cd9ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerics_only = imputted_data.select_dtypes(include=np.number)\n",
    "df_numerics_only.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5fa947-a504-40b8-aa84-aaab0265a230",
   "metadata": {},
   "source": [
    "### Fraud ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728fbbc-5289-48b9-a7e8-ea2ac8186576",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts = imputted_data.default_ind.value_counts()\n",
    "print(val_counts)\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('No Frauds', round(imputted_data['default_ind'].value_counts()[0]/len(imputted_data) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(imputted_data['default_ind'].value_counts()[1]/len(imputted_data) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5860c-9193-47c8-89b3-ad2038826761",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870a0cd-91d0-4493-9f83-b055d2f8ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputted_data.drop('default_ind', axis=1)\n",
    "y = imputted_data['default_ind']\n",
    " \n",
    "original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(\n",
    "X, y, test_size=0.33, random_state=42, shuffle=True, stratify=y)  \n",
    "    \n",
    "    \n",
    "# Turn into an array\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "# See if both the train and test label distribution are similarly distributed\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(original_ytrain))\n",
    "print(test_counts_label/ len(original_ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88abbe30-19a2-4ada-a164-ea2b8e8a2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the new dataframe to keep all the results\n",
    "Comparingdata = pd.DataFrame(columns =['Classifier',\n",
    "                                       'Accuracy',\n",
    "                                       'Balanced_Accuracy',\n",
    "                                       'Precision',\n",
    "                                       'Recall',\n",
    "                                       'MCC',\n",
    "                                       'Execution_time',\n",
    "                                       'Best_param'])\n",
    "Comparingdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dce2b9-3e19-465f-bad0-3b418d60e3ba",
   "metadata": {},
   "source": [
    "# Classifiers tuned with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace6b89-115c-40dc-82eb-94b2546d5971",
   "metadata": {},
   "outputs": [],
   "source": [
    "RScal = RobustScaler()\n",
    "sss = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'balanced_accuracy': 'balanced_accuracy',\n",
    "           'precision': 'precision',\n",
    "           'recall': 'recall',\n",
    "           'MCC': make_scorer(matthews_corrcoef)\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164d6d9-9b5a-4e78-aeba-c3fc50c1f974",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier - NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ded4d-6cff-48e1-9fa8-fddd3b080243",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', GaussianNB())])\n",
    "\n",
    "param_grid = {\n",
    " 'classifier__var_smoothing': [0.0001,0.001,0.01]}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, verbose=3)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "scores = cross_validate (search, original_Xtrain, original_ytrain, scoring=scoring ,cv=sss, verbose=3)\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(scores['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(scores['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(scores['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(scores['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(scores['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "print('-------------------------------')\n",
    "\n",
    "\n",
    "# Searching for the best parameters\n",
    "search.fit(original_Xtrain, original_ytrain)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "# Adding information into the dataframe\n",
    "\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'NB_GridSearch',\n",
    "                                      'Accuracy': scores['test_accuracy'].mean(), \n",
    "                                      'Balanced_Accuracy': scores['test_balanced_accuracy'].mean(),\n",
    "                                      'Precision': scores['test_precision'].mean(), \n",
    "                                      'Recall': scores['test_recall'].mean(),\n",
    "                                      'MCC': scores['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': search.best_params_}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f41ec73-01ab-4bc7-b4aa-ed4396e7d390",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier - DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e5f76-dd9c-4cd3-83c9-e4d400e12663",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {    'max_depth': [2,3,4,5,10,15.20,25,30,35,40,45],\n",
    "                  'max_features': ['sqrt', 'log2'],\n",
    "                  'min_samples_leaf': [2,4,6,8],\n",
    "                  'min_samples_split': [2,3,5,7]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(DecisionTreeClassifier(), param_grid, n_jobs=-1, verbose=3)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "scores = cross_validate(search, original_Xtrain, original_ytrain,scoring=scoring,cv=sss, verbose=3)\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(scores['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(scores['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(scores['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(scores['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(scores['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "print('-------------------------------')\n",
    "\n",
    "\n",
    "# Searching for the best parameters\n",
    "search.fit(original_Xtrain, original_ytrain)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'DT_GridSearch',\n",
    "                                      'Accuracy': scores['test_accuracy'].mean(), \n",
    "                                      'Balanced_Accuracy': scores['test_balanced_accuracy'].mean(),\n",
    "                                      'Precision': scores['test_precision'].mean(), \n",
    "                                      'Recall': scores['test_recall'].mean(),\n",
    "                                      'MCC': scores['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': search.best_params_}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c2676-cb1c-478b-bce7-b0bafd515ad5",
   "metadata": {},
   "source": [
    "## Super vector classifier - SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd61280-396c-4eb7-9825-8b7c491431ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', SVC())])\n",
    "\n",
    "param_grid = {\n",
    "                  'classifier__C': [10,100,200],\n",
    "                  'classifier__kernel': ['poly', 'rbf','sigmoid'],\n",
    "                  'classifier__gamma': [0.01, 0.001]\n",
    "                 }\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, verbose=3)\n",
    "\n",
    "\n",
    "Sstart_time = time.time()\n",
    "scores = cross_validate(search, original_Xtrain, original_ytrain, scoring=scoring,cv=sss, verbose = 3)\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(scores['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(scores['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(scores['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(scores['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(scores['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "print('-------------------------------')\n",
    "\n",
    "\n",
    "# Searching for the best parameters\n",
    "search.fit(original_Xtrain, original_ytrain)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'SVC_GridSearch',\n",
    "                                      'Accuracy': scores['test_accuracy'].mean(), \n",
    "                                      'Balanced_Accuracy': scores['test_balanced_accuracy'].mean(),\n",
    "                                      'Precision': scores['test_precision'].mean(), \n",
    "                                      'Recall': scores['test_recall'].mean(),\n",
    "                                      'MCC': scores['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': search.best_params_}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e5f7c-567c-47a8-b245-0eb1c434761d",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb3bc9d-f7a4-4edd-9ba1-804b45aa65aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', KNeighborsClassifier())])\n",
    "\n",
    "param_grid = {    'classifier__metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "                  'classifier__n_neighbors': [17,19,21,23]}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1, verbose=3)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "scores = cross_validate(search, original_Xtrain, original_ytrain, scoring=scoring,cv=sss, verbose = 3)\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(scores['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(scores['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(scores['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(scores['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(scores['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time)) \n",
    "print('-------------------------------')\n",
    "\n",
    "\n",
    "# Searching for the best parameters\n",
    "search.fit(original_Xtrain, original_ytrain)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'KNN_GridSearch',\n",
    "                                      'Accuracy': scores['test_accuracy'].mean(), \n",
    "                                      'Balanced_Accuracy': scores['test_balanced_accuracy'].mean(),\n",
    "                                      'Precision': scores['test_precision'].mean(), \n",
    "                                      'Recall': scores['test_recall'].mean(),\n",
    "                                      'MCC': scores['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': search.best_params_}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da1395-3858-426c-ad7f-cf8a60d261f3",
   "metadata": {},
   "source": [
    "## Bagging on DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c45b7d0-6828-4bdd-8287-34da2e6fc1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {      'n_estimators': [10, 30, 50],\n",
    "                    'bootstrap': [True, False]\n",
    "                    }\n",
    "\n",
    "search = GridSearchCV(BaggingClassifier(), param_grid, n_jobs=-1, verbose=3)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "scores = cross_validate(search, original_Xtrain, original_ytrain,scoring=scoring,cv=sss, verbose=3)\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(scores['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(scores['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(scores['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(scores['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(scores['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))   \n",
    "print('-------------------------------')\n",
    "\n",
    "\n",
    "# Searching for the best parameters\n",
    "search.fit(original_Xtrain, original_ytrain)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'Bagging_GridSearch',\n",
    "                                      'Accuracy': scores['test_accuracy'].mean(), \n",
    "                                      'Balanced_Accuracy': scores['test_balanced_accuracy'].mean(),\n",
    "                                      'Precision': scores['test_precision'].mean(), \n",
    "                                      'Recall': scores['test_recall'].mean(),\n",
    "                                      'MCC': scores['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': search.best_params_}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc768c7-dcff-471d-8fa4-4f9e8c28bc1d",
   "metadata": {},
   "source": [
    "## Random Forest Classifier - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3249cdd-fa35-4d1f-9893-197f520803ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {   'bootstrap': [True, False],\n",
    "                 'max_depth': [10, 15, 20],\n",
    "                 'max_features': [0.01,0.1,0.5],\n",
    "                 'n_estimators': [10, 50, 100]}\n",
    "\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=-1, verbose=3)\n",
    "\n",
    "start_time = time.time()\n",
    "scores = cross_validate(search, original_Xtrain, original_ytrain,scoring=scoring,cv=sss, verbose=3)\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(scores['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(scores['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(scores['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(scores['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(scores['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))    \n",
    "print('-------------------------------')\n",
    "\n",
    "# Searching for the best parameters\n",
    "search.fit(original_Xtrain, original_ytrain)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'RF_GridSearch',\n",
    "                                      'Accuracy': scores['test_accuracy'].mean(), \n",
    "                                      'Balanced_Accuracy': scores['test_balanced_accuracy'].mean(),\n",
    "                                      'Precision': scores['test_precision'].mean(), \n",
    "                                      'Recall': scores['test_recall'].mean(),\n",
    "                                      'MCC': scores['test_MCC'].mean(), \n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': search.best_params_}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a4db94-e49f-441b-9495-bc98a610df85",
   "metadata": {},
   "source": [
    "## XGBClassifier - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a02ca-e494-4ad5-b751-026b46804b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {      'n_estimators': [10, 30,50],\n",
    "                    'colsample_bytree': [0.4, 0.5 , 0.7],\n",
    "                    'max_depth': [10,20,30],\n",
    "                    'learning_rate': [0.001,0.01]\n",
    "                    }\n",
    "\n",
    "search = GridSearchCV(xgb.XGBClassifier(), param_grid, n_jobs=-1, verbose=3)\n",
    "\n",
    "start_time = time.time()\n",
    "scores = cross_validate(search, original_Xtrain, original_ytrain,scoring=scoring,cv=sss, verbose=3)\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(scores['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(scores['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(scores['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(scores['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(scores['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))    \n",
    "print('-------------------------------')\n",
    "\n",
    "\n",
    "# Searching for the best parameters\n",
    "search.fit(original_Xtrain, original_ytrain)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'XGBoost_GridSearch',\n",
    "                                      'Accuracy': scores['test_accuracy'].mean(), \n",
    "                                      'Balanced_Accuracy': scores['test_balanced_accuracy'].mean(),\n",
    "                                      'Precision': scores['test_precision'].mean(), \n",
    "                                      'Recall': scores['test_recall'].mean(),\n",
    "                                      'MCC': scores['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': search.best_params_}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4671bd9-1c81-4bba-8bd2-adc78026c895",
   "metadata": {},
   "source": [
    "## LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f12ac-e738-4b07-b7d2-c6b8c30e40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {      'n_estimators': [900,1000,1100],\n",
    "                    'max_depth': [8,9,10,11,12],\n",
    "                    'learning_rate': [0.001, 0.01,0.1],\n",
    "                    'feature_fraction': [0.2,0.3,0.4],\n",
    "                    'boosting_type': ['gbdt', 'dart', 'goss']\n",
    "                    }\n",
    "\n",
    "search = GridSearchCV(lgb.LGBMClassifier(), param_grid, n_jobs=-1, verbose=3)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "scores = cross_validate(search, original_Xtrain, original_ytrain,scoring=scoring,cv=sss, verbose=3)\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "print(\"Average Accuracy: {}\".format(scores['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(scores['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(scores['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(scores['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(scores['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "print('-------------------------------')\n",
    "\n",
    "\n",
    "# Searching for the best parameters\n",
    "search.fit(original_Xtrain, original_ytrain)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'LightGBM_GridSearch',\n",
    "                                      'Accuracy': scores['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': scores['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': scores['test_precision'].mean(), \n",
    "                                      'Recall': scores['test_recall'].mean(),\n",
    "                                      'MCC': scores['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': search.best_params_}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29c3e12-db7c-459f-a0cd-d1c7dbd27bda",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0400d5-76c5-4365-9db7-84fb41a9aaac",
   "metadata": {},
   "source": [
    "# Classifiers tuned with HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f41b3e-9058-4c72-8fe2-861cf636ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, random_state=42, cv=sss, X=original_Xtrain, y=original_ytrain):\n",
    "    score = cross_val_score(pipe, X, y,cv=sss, scoring = 'accuracy', n_jobs=-1).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90473672-cb69-431e-9aa5-921d90457372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(params, random_state=42, cv=sss, X=original_Xtrain, y=original_ytrain):\n",
    "\n",
    "    score = cross_validate(pipe, X, y,cv=sss, scoring = scoring, n_jobs=-1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4691bbdd-79bb-45b3-b3bf-ffa4019ffd71",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71154aad-cf1b-4bad-8ca0-f2da8beddd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', GaussianNB())])\n",
    "\n",
    "space = {\n",
    "    'classifier__var_smoothing': hp.quniform('classifier__var_smoothing',0,1,0.0001)\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'NB_HyperOpt',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f73e86-8114-4165-9093-bf6971a3db97",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3230546-620f-4140-97a2-f65759e46f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= DecisionTreeClassifier()\n",
    "\n",
    "space = {\n",
    "                  'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "                  'max_depth': hp.quniform('max_depth', 3,15,1),\n",
    "                  'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "                  'min_samples_leaf': hp.uniform('min_samples_leaf',1,5),\n",
    "                  'min_samples_split': hp.uniform('min_samples_split',1,8)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "print('Best parameters: {}'.format(best_param))\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'DT_HyperOpt',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505b6e80-e123-4d43-9d18-53646c19f082",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26ff09-1ed6-4696-8680-c61caae3d1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', SVC())])\n",
    "\n",
    "space = {\n",
    "                 \n",
    "            'classifier__C': hp.choice('classifier__C', [10, 100, 1000, 10000]),\n",
    "            'classifier__gamma': hp.choice('classifier__gamma', [0.01, 0.001, 0.0001]),\n",
    "            'classifier__kernel': hp.choice('classifier__kernel', ['poly', 'rbf','sigmoid'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'SVC_HyperOpt',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d72c29-a57a-4e8e-89d8-4dc220d93a04",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf228b2-19f8-49ca-9f1f-a7f482cb0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', KNeighborsClassifier())])\n",
    "\n",
    "space = {\n",
    "                'classifier__metric': hp.choice('classifier__metric', ['euclidean', 'manhattan','minkowski']),\n",
    "                'classifier__n_neighbors': hp.uniform('classifier__n_neighbors', 10,20)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperopt will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'KNN_HyperOpt',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d400526d-2157-4b89-b73d-cbeb8d90f310",
   "metadata": {},
   "source": [
    "## Bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c379d3-a407-4194-adc5-447a6b59e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= BaggingClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'classifier__max_features': hp.quniform('classifier__max_features',10,50,1),\n",
    "            'classifier__bootstrap': hp.choice('classifier__bootstrap', [True, False]),\n",
    "            'classifier__bootstrap_features': hp.choice('classifier__bootstrap_features', [True, False])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'Bagging_HyperOpt',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31e4019-2313-4598-8653-bdd5e5cba471",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6b18f-55c5-40a6-aa01-256970d9f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= RandomForestClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'max_depth': hp.quniform('max_depth', 1, 30, 1),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            'max_features': hp.uniform('max_features', 0.0001,1),\n",
    "            'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "            'min_samples_split':hp.uniform('min_samples_split',2,6)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'RF_HyperOpt',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66e04a-2e41-4c9f-b917-bca0b8d0bd92",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36eead-ee6b-48e3-90b3-3f5633cf0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= xgb.XGBClassifier()\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 30, 1),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1),\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 250, 10)),\n",
    "    'min_child_samples': hp.choice('min_child_samples', range(100, 250, 10)),\n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', range(200,10000, 100))\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'XGBoost_HyperOpt',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e16b2e-231a-482b-9522-1a2c1eb7d8fe",
   "metadata": {},
   "source": [
    "## LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754fa4d-2ce1-431a-89c9-f9a90e11612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= lgb.LGBMClassifier()\n",
    "\n",
    "space = {\n",
    "        'num_leaves': hp.choice('num_leaves',range(1,1000,1)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,20,1)),\n",
    "        'lambda_l1': hp.choice('lambda_l1', range(0, 100, 5)),\n",
    "        'lambda_l2': hp.choice('lambda_l2', range(0, 100, 5)),\n",
    "        'learning_rate': hp.quniform('learning_rate', 0, 0.5, 0.001),\n",
    "        'min_data_in_leaf': hp.choice('min_data_in_leaf', range(200,10000, 100)),\n",
    "        'max_bin': hp.uniform('max_bin', 200, 300),\n",
    "        'min_gain_to_split': hp.uniform('min_gain_to_split', 0,15),\n",
    "        'n_estimators': hp.choice('n_estimators', range(100,10000, 100)),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss', 'rf'])\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'LightGBM_HyperOpt',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ddb13-e84e-4e8a-8343-71fd7d8b34a8",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36adc0d9-8f59-4d71-8730-b6fb6e90e5d2",
   "metadata": {},
   "source": [
    "## Random Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29689769-f861-4c98-a290-52dcdc9e809d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Single Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90c197-67cc-407c-a4cb-3d658cca2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total =0\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        sampling=RandomUnderSampler()\n",
    "        X_sampling, y_sampling = sampling.fit_resample(X_train, y_train)\n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        s=pipe.score(X_test, y_test)\n",
    "        total= total + s\n",
    "    score = total/5            \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851c91d-5942-41f1-84be-663ee590a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "def score_resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total_accuracy =np.array([])\n",
    "    total_balanced_accuracy =np.array([])\n",
    "    total_precision =np.array([])\n",
    "    total_recall =np.array([])\n",
    "    total_MCC =np.array([])\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        sampling=RandomUnderSampler()\n",
    "        X_sampling, y_sampling = sampling.fit_resample(X_train, y_train)\n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Calculation\n",
    "        test_accuracy=accuracy_score(y_test, y_pred)\n",
    "        test_balanced_accuracy=balanced_accuracy_score(y_test, y_pred)\n",
    "        test_precision=precision_score(y_test, y_pred)\n",
    "        test_recall=recall_score(y_test, y_pred)\n",
    "        test_MCC=matthews_corrcoef(y_test, y_pred)\n",
    "        \n",
    "        total_accuracy =np.append(total_accuracy ,np.array([test_accuracy]), axis=0)\n",
    "        total_balanced_accuracy =np.append(total_balanced_accuracy ,np.array([test_balanced_accuracy]), axis=0)\n",
    "        total_precision =np.append(total_precision ,np.array([test_precision]), axis=0)\n",
    "        total_recall =np.append(total_recall ,np.array([test_recall]), axis=0)\n",
    "        total_MCC =np.append(total_MCC ,np.array([test_MCC]), axis=0)\n",
    "           \n",
    "    metrics = {}\n",
    "    metrics['test_accuracy']= total_accuracy\n",
    "    metrics['test_balanced_accuracy']=total_balanced_accuracy\n",
    "    metrics['test_precision']=total_precision\n",
    "    metrics['test_recall']=total_recall\n",
    "    metrics['test_MCC']=total_MCC\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9df076-0de3-4361-b56c-bed236b73db4",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b0a81a-5de5-4d2a-88de-32bcb04d0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', GaussianNB())])\n",
    "\n",
    "space = {\n",
    "'classifier__var_smoothing': hp.quniform('classifier__var_smoothing',0,1,0.0001)}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'NB_RUS',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91256f4-3494-4fdf-8560-174ef2e98c9c",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89a671-0a3c-4897-9c8e-227b285bc130",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= DecisionTreeClassifier()\n",
    "\n",
    "space = {\n",
    "                  'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "                  'max_depth': hp.quniform('max_depth', 3,15,1),\n",
    "                  'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "                  'min_samples_leaf': hp.uniform('min_samples_leaf',1,5),\n",
    "                  'min_samples_split': hp.uniform('min_samples_split',1,8)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "print('Best parameters: {}'.format(best_param))\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'DT_RUS',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9144e06-5009-498e-b6d4-52e4b21565b1",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c10846-52b5-4f96-9855-832b380b72b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', SVC())])\n",
    "\n",
    "space = {\n",
    "                 \n",
    "            'classifier__C': hp.choice('classifier__C', [10, 100, 1000, 10000]),\n",
    "            'classifier__gamma': hp.choice('classifier__gamma', [0.01, 0.001, 0.0001]),\n",
    "            'classifier__kernel': hp.choice('classifier__kernel', ['poly', 'rbf','sigmoid'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'SVC_RUS',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569cb26-5f93-47df-9d7f-c4c44f853f9e",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f1a18e-d507-4479-bb78-17b759587d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', KNeighborsClassifier())])\n",
    "\n",
    "space = {\n",
    "                'classifier__metric': hp.choice('classifier__metric', ['euclidean', 'manhattan','minkowski']),\n",
    "                'classifier__n_neighbors': hp.uniform('classifier__n_neighbors', 10,20)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperopt will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'KNN_RUS',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2226529-a089-49fe-ad10-f8452a29f6fc",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c851a245-29ca-4773-8598-42a8f1817df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= BaggingClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'classifier__max_features': hp.quniform('classifier__max_features',10,50,1),\n",
    "            'classifier__bootstrap': hp.choice('classifier__bootstrap', [True, False]),\n",
    "            'classifier__bootstrap_features': hp.choice('classifier__bootstrap_features', [True, False])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'Bagging_RUS',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6af84f-50e1-44b3-b8d3-1404d380536c",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a89756-248a-4d6c-80e2-dc6d6d209309",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= RandomForestClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'max_depth': hp.quniform('max_depth', 1, 30, 1),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            'max_features': hp.uniform('max_features', 0.0001,1),\n",
    "            'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "            'min_samples_split':hp.uniform('min_samples_split',2,6)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'RF_RUS',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922b6c2-e2cb-44ca-abb9-a421cd010943",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37edee21-ae47-4ec6-be1d-439e38fab352",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= xgb.XGBClassifier()\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 30, 1),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1),\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 250, 10)),\n",
    "    'min_child_samples': hp.choice('min_child_samples', range(100, 250, 10)),\n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', range(200,10000, 100))\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'XGBoost_RUS',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06473a03-b766-4a85-9171-5f1a077a77be",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2565c16-9fa6-4094-9842-59d4201cd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= lgb.LGBMClassifier()\n",
    "\n",
    "space = {\n",
    "        'num_leaves': hp.choice('num_leaves',range(20,3000,20)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,15,1)),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0, 1),\n",
    "        'feature_fraction':  hp.uniform('feature_fraction', 0, 1),\n",
    "        'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 0.0005, 0.010),\n",
    "        'lambda_l1': hp.choice('lambda_l1', range(0, 100, 5)),\n",
    "        'lambda_l2': hp.choice('lambda_l2', range(0, 100, 5)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'min_data_in_leaf': hp.choice('min_data_in_leaf', range(200,10000, 100)),\n",
    "        'max_bin': hp.uniform('max_bin', 200, 300),\n",
    "        'min_gain_to_split': hp.uniform('min_gain_to_split', 0,15),\n",
    "        'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss', 'rf'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'LightGBM_RUS',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927da33f-c7b4-423a-a2a3-ea5b2f60bcb8",
   "metadata": {},
   "source": [
    "## SMOTE & TomekLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac97f7-6749-46f4-a540-6d9e9ca3042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total =0\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        sampling=SMOTETomek(tomek=TomekLinks())\n",
    "        X_sampling, y_sampling = sampling.fit_resample(X_train, y_train)\n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        s=pipe.score(X_test, y_test)\n",
    "        total= total + s\n",
    "    score = total/5            \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e313a6-72d4-4692-9189-2a37c56f3d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "def score_resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total_accuracy =np.array([])\n",
    "    total_balanced_accuracy =np.array([])\n",
    "    total_precision =np.array([])\n",
    "    total_recall =np.array([])\n",
    "    total_MCC =np.array([])\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        sampling=SMOTETomek(tomek=TomekLinks())\n",
    "        X_sampling, y_sampling = sampling.fit_resample(X_train, y_train)\n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Calculation\n",
    "        test_accuracy=accuracy_score(y_test, y_pred)\n",
    "        test_balanced_accuracy=balanced_accuracy_score(y_test, y_pred)\n",
    "        test_precision=precision_score(y_test, y_pred)\n",
    "        test_recall=recall_score(y_test, y_pred)\n",
    "        test_MCC=matthews_corrcoef(y_test, y_pred)\n",
    "        \n",
    "        total_accuracy =np.append(total_accuracy ,np.array([test_accuracy]), axis=0)\n",
    "        total_balanced_accuracy =np.append(total_balanced_accuracy ,np.array([test_balanced_accuracy]), axis=0)\n",
    "        total_precision =np.append(total_precision ,np.array([test_precision]), axis=0)\n",
    "        total_recall =np.append(total_recall ,np.array([test_recall]), axis=0)\n",
    "        total_MCC =np.append(total_MCC ,np.array([test_MCC]), axis=0)\n",
    "           \n",
    "    metrics = {}\n",
    "    metrics['test_accuracy']= total_accuracy\n",
    "    metrics['test_balanced_accuracy']=total_balanced_accuracy\n",
    "    metrics['test_precision']=total_precision\n",
    "    metrics['test_recall']=total_recall\n",
    "    metrics['test_MCC']=total_MCC\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08038538-f7e8-4929-8015-9ef377ea7b68",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f7afc7-f458-4b75-b897-9dda5479fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', GaussianNB())])\n",
    "\n",
    "space = {\n",
    "        'classifier__var_smoothing': hp.quniform('classifier__var_smoothing',0,1,0.0001)}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'NB_SmoteTomek',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc7d7c-16af-4044-ba5b-d28a3cb1e6bc",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b9f91-1e78-400b-8ae5-b2b1f91e5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= DecisionTreeClassifier()\n",
    "\n",
    "space = {\n",
    "                  'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "                  'max_depth': hp.quniform('max_depth', 3,15,1),\n",
    "                  'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "                  'min_samples_leaf': hp.uniform('min_samples_leaf',1,5),\n",
    "                  'min_samples_split': hp.uniform('min_samples_split',1,8)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "print('Best parameters: {}'.format(best_param))\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'DT_SmoteTomek',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02380b65-309f-4f44-ba5b-484e618c6705",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113069a-0fe9-44ba-8b6e-b8b914955c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', SVC())])\n",
    "\n",
    "space = {\n",
    "                 \n",
    "            'classifier__C': hp.choice('classifier__C', [10, 100, 1000, 10000]),\n",
    "            'classifier__gamma': hp.choice('classifier__gamma', [0.01, 0.001, 0.0001]),\n",
    "            'classifier__kernel': hp.choice('classifier__kernel', ['poly', 'rbf','sigmoid'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'SVC_SmoteTomek',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b732102-ca67-4456-b4f0-1a3adceba9b7",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca4313-c6a6-48b2-97d9-556ad6f891c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', KNeighborsClassifier())])\n",
    "\n",
    "space = {\n",
    "                'classifier__metric': hp.choice('classifier__metric', ['euclidean', 'manhattan','minkowski']),\n",
    "                'classifier__n_neighbors': hp.uniform('classifier__n_neighbors', 10,20)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperopt will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'KNN_SmoteTomek',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23efbe33-8585-496d-95a8-ad40ae65554e",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68dca2-f3a9-47f1-b1f0-b1257ab9b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= BaggingClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'classifier__max_features': hp.quniform('classifier__max_features',10,50,1),\n",
    "            'classifier__bootstrap': hp.choice('classifier__bootstrap', [True, False]),\n",
    "            'classifier__bootstrap_features': hp.choice('classifier__bootstrap_features', [True, False])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'Bagging_SmoteTomek',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb3cd0-30fe-4528-a1c2-e4bad532a010",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc497d09-4a2f-4df3-9eea-d176fb3e765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= RandomForestClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'max_depth': hp.quniform('max_depth', 1, 30, 1),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            'max_features': hp.uniform('max_features', 0.0001,1),\n",
    "            'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "            'min_samples_split':hp.uniform('min_samples_split',2,6)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'RF_SmoteTomek',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d591b4d0-a6f2-49f0-9d72-b24bca0bfb9c",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62a047-5612-4a63-8ffb-c58d19245fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= xgb.XGBClassifier()\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 30, 1),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1),\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 250, 10)),\n",
    "    'min_child_samples': hp.choice('min_child_samples', range(100, 250, 10)),\n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', range(200,10000, 100))\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'XGBoost_SmoteTomek',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb46cca-6ce9-4e6f-b381-4612a05dd6d1",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a1935-65cb-4f6b-821b-8acbb9a99613",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= lgb.LGBMClassifier()\n",
    "\n",
    "space = {\n",
    "        'num_leaves': hp.choice('num_leaves',range(20,3000,20)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,15,1)),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0, 1),\n",
    "        'feature_fraction':  hp.uniform('feature_fraction', 0, 1),\n",
    "        'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 0.0005, 0.010),\n",
    "        'lambda_l1': hp.choice('lambda_l1', range(0, 100, 5)),\n",
    "        'lambda_l2': hp.choice('lambda_l2', range(0, 100, 5)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'min_data_in_leaf': hp.choice('min_data_in_leaf', range(200,10000, 100)),\n",
    "        'max_bin': hp.uniform('max_bin', 200, 300),\n",
    "        'min_gain_to_split': hp.uniform('min_gain_to_split', 0,15),\n",
    "        'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss', 'rf'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'LightGBM_SmoteTomek',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69e9f33-c2ea-4f4f-b98c-77b91605a4dc",
   "metadata": {},
   "source": [
    "## IW-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d2d18f-789e-4b90-878a-52a731b8298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classfication and regression tree\n",
    "def CART(X=original_Xtrain, y=original_ytrain, XX=original_Xtest):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X, y)\n",
    "    predicted = model.predict(XX)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "class IW_SMOTE():\n",
    "    def __init__(self, data, target, balance=1):\n",
    "        self.balance = balance;  # Sampling rate\n",
    "        self.data = original_Xtrain # The training set\n",
    "        self.target = original_ytrain # The labels of training set\n",
    "\n",
    "    \"\"\"\n",
    "            :param lamda: lamda*imbalance ratio = the number of cart\n",
    "            :param thres: The threshold of filtering noise\n",
    "            :param k_neighbor: k nearest neighbor\n",
    "            :param divide_times: The ratio of under sampling minority samples\n",
    "            :param gen_times: The ratio of generated minority class to majority class samples\n",
    "            :return: The synthetic samples, attributes and labels\n",
    "    \"\"\"\n",
    "    def IW_SMOTE(self, lamda=100, thres=0.5, divide_times=2, gen_times=1, k_neighbor=5):\n",
    "        # x_x:Temporary variable, save the training set\n",
    "        x_x = pd.DataFrame(self.data)\n",
    "        x_x[len(x_x.columns)] = self.target\n",
    "        m, n = len(x_x), len(x_x.columns) #m: the number of trainning set; n: the number of columns of the trainning set\n",
    "        z = x_x[x_x[n - 1] == 1]  # acquire the minority set\n",
    "        p = x_x[x_x[n - 1] == -1]  # acquire the majority set\n",
    "        m1, n1 = len(z), len(z.columns) # m1: the number of minority samples; n1: the number of columns of the minority samples\n",
    "        m2, n2 = len(p), len(p.columns) # m2: the number of majority samples; n2: the number of columns of the majority samples\n",
    "        IR = m2 / m1  # imbalance ratio\n",
    "        predict_min_labelset = pd.DataFrame(columns = range(int(IR * lamda))) # the predicted labels of the minority samples\n",
    "        predict_maj_labelset = pd.DataFrame(columns = range(int(IR * lamda))) # the predicted labels of the majority samples\n",
    "        # train under-bagging CART\n",
    "        for i_1 in range(int(IR * lamda)):\n",
    "            train_subset = z.sample(int(m1 / divide_times)) # train_subset: the subset of training set\n",
    "            train_subset = train_subset.append(p.sample(int(m1 / divide_times), replace=True))\n",
    "            predict_maj_labelset[i_1] = CART(np.array(train_subset.iloc[:, 0:n1 - 1]), np.array(train_subset[n1 - 1]),\n",
    "                                             np.array(p.iloc[:, 0:n2 - 1]))\n",
    "            predict_min_labelset[i_1] = CART(np.array(train_subset.iloc[:, 0:n1 - 1]), np.array(train_subset[n1 - 1]),\n",
    "                                             np.array(z.iloc[:, 0:n1 - 1]))\n",
    "        # filterring noise\n",
    "        err_rate_min = []  # record the error rate of the reserved minority instance\n",
    "        reserve_min = []  # record the reserved minority instances\n",
    "        num_reserve_min = 0  # the number of minority samples after denoising\n",
    "        z1 = np.array(z)\n",
    "        predict_min_labelset = np.array(predict_min_labelset)\n",
    "        for i_2 in range(m1):\n",
    "            num_right = 0  # record the number of instance which is predicted accurately\n",
    "            for j in range(int(IR * lamda)):\n",
    "                if predict_min_labelset[i_2][j] == z1[i_2][n1 - 1]:\n",
    "                    num_right = num_right + 1\n",
    "            if ((int(IR * lamda) - num_right) / int(IR * lamda) < thres):\n",
    "                num_reserve_min += 1\n",
    "                reserve_min.append(z1[i_2])\n",
    "                if (int(IR * lamda) - num_right) / int(IR * lamda) < 1 / int(IR * lamda):\n",
    "                    err_rate_min.append(1 / int(IR * lamda))\n",
    "                else:\n",
    "                    err_rate_min.append((int(IR * lamda) - num_right) / int(IR * lamda))\n",
    "        reserve_min = pd.DataFrame(reserve_min)\n",
    "        err_rate_min = pd.DataFrame(err_rate_min)\n",
    "        err_rate_maj = []  # record the error rate of the reserved minority instance\n",
    "        reserve_maj = []  # record the reserved minority instances\n",
    "        num_reserve_maj = 0  # the number of majority samples after denoising\n",
    "        p1 = np.array(p)\n",
    "        predict_maj_labelset = np.array(predict_maj_labelset)\n",
    "        for i_3 in range(m2):\n",
    "            num_right = 0  # record the number of instance which is predicted accurately\n",
    "            for j in range(int(IR * lamda)):\n",
    "                if predict_maj_labelset[i_3][j] == p1[i_3][n2 - 1]:\n",
    "                    num_right = num_right + 1\n",
    "            if ((int(IR * lamda) - num_right) / int(IR * lamda) < thres):\n",
    "                num_reserve_maj += 1\n",
    "                reserve_maj.append(p1[i_3])\n",
    "                if (int(IR * lamda) - num_right) / int(IR * lamda) < 1 / int(IR * lamda):\n",
    "                    err_rate_maj.append(1 / int(IR * lamda))\n",
    "                else:\n",
    "                    err_rate_maj.append((int(IR * lamda) - num_right) / int(IR * lamda))\n",
    "        reserve_maj = pd.DataFrame(reserve_maj)\n",
    "\n",
    "        # generate the synthetic minority instances\n",
    "        weight = err_rate_min[0] / sum(err_rate_min[0])  # Record the importance of each sample\n",
    "        num_need_generate = gen_times * num_reserve_maj - num_reserve_min  # The number of minority samples that need to be synthesized\n",
    "        if num_need_generate == num_reserve_maj:\n",
    "            return np.array(reserve_maj.iloc[:, 0:len(reserve_maj.columns) - 1]), np.array(\n",
    "                reserve_maj[len(reserve_maj.columns) - 1])\n",
    "        else:\n",
    "            num_generate = 0 # the number of be generated\n",
    "            new_set = pd.DataFrame(columns=range(n1))\n",
    "            for i_4 in range(num_reserve_min):\n",
    "                reserve_min_1 = reserve_min\n",
    "                nums = pd.DataFrame(weight * (gen_times * num_reserve_maj - num_reserve_min)).iloc[i_4, 0]\n",
    "                reserve_min_1 = np.array(reserve_min_1)\n",
    "                dis = [0] * num_reserve_min # distance matrix of per sample\n",
    "                for m in range(num_reserve_min):\n",
    "                    dis[m] = np.linalg.norm(reserve_min_1[i_4] - reserve_min_1[m])\n",
    "                b = sorted(enumerate(dis), key=lambda xxx: xxx[1]) #Sorted dis\n",
    "                b = b[1:k_neighbor + 1] # choice knn\n",
    "                for j in range(int(nums)):\n",
    "                    num_generate = num_generate + 1\n",
    "                    s_b = random.choice(b)\n",
    "                    select_ins = reserve_min.iloc[s_b[0], :]\n",
    "                    new_ins = (reserve_min.iloc[i_4, :] - pd.DataFrame(select_ins).T) * random.random() + pd.DataFrame(\n",
    "                        select_ins).T  # generate funtion\n",
    "                    new_set = new_set.append(pd.DataFrame(new_ins))  # add the new instance into a temporary set\n",
    "            new_z = reserve_min.append(new_set) # The minority synthetic samples\n",
    "            new_original_data = reserve_maj.append(new_z) # The synthetic samples\n",
    "            new_original_data.index = range(len(new_original_data))\n",
    "            # Returns an oversampled dataset\n",
    "            return np.array(new_original_data.iloc[:, 0:len(new_original_data.columns) - 1]), np.array(new_original_data[len(new_original_data.columns) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456daa14-130d-41aa-8e67-6007c2605eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total_accuracy =np.array([])\n",
    "    total_balanced_accuracy =np.array([])\n",
    "    total_precision =np.array([])\n",
    "    total_recall =np.array([])\n",
    "    total_MCC =np.array([])\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_sampling =IW_SMOTE(X_train, y_train).data\n",
    "        y_sampling =IW_SMOTE(X_train, y_train).target \n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Calculation\n",
    "        test_accuracy=accuracy_score(y_test, y_pred)\n",
    "        test_balanced_accuracy=balanced_accuracy_score(y_test, y_pred)\n",
    "        test_precision=precision_score(y_test, y_pred)\n",
    "        test_recall=recall_score(y_test, y_pred)\n",
    "        test_MCC=matthews_corrcoef(y_test, y_pred)\n",
    "        \n",
    "        total_accuracy =np.append(total_accuracy ,np.array([test_accuracy]), axis=0)\n",
    "        total_balanced_accuracy =np.append(total_balanced_accuracy ,np.array([test_balanced_accuracy]), axis=0)\n",
    "        total_precision =np.append(total_precision ,np.array([test_precision]), axis=0)\n",
    "        total_recall =np.append(total_recall ,np.array([test_recall]), axis=0)\n",
    "        total_MCC =np.append(total_MCC ,np.array([test_MCC]), axis=0)\n",
    "           \n",
    "    metrics = {}\n",
    "    metrics['test_accuracy']= total_accuracy\n",
    "    metrics['test_balanced_accuracy']=total_balanced_accuracy\n",
    "    metrics['test_precision']=total_precision\n",
    "    metrics['test_recall']=total_recall\n",
    "    metrics['test_MCC']=total_MCC\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a5a72-8838-452c-ab1e-5f451b738789",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c2bd0-234c-4570-a2bf-1bfe4309240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', GaussianNB())])\n",
    "\n",
    "space = {\n",
    "'classifier__var_smoothing': hp.quniform('classifier__var_smoothing',0,1,0.0001)}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"/n Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"/n Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"/n Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"/n Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"/n Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'NB_IWSmote',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e689f2f7-6cea-4852-880d-543e20ec5574",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc9e6d-19fa-45dc-b3de-c0d13dfb185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= DecisionTreeClassifier()\n",
    "\n",
    "space = {\n",
    "                  'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "                  'max_depth': hp.quniform('max_depth', 3,15,1),\n",
    "                  'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "                  'min_samples_leaf': hp.uniform('min_samples_leaf',1,5),\n",
    "                  'min_samples_split': hp.uniform('min_samples_split',1,8)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "print('Best parameters: {}'.format(best_param))\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'DT_IWSmote',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1c0db-d418-4647-aa25-66f294ece74c",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99215616-c80a-4dad-bdca-76fb7979799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', SVC())])\n",
    "\n",
    "space = {\n",
    "                 \n",
    "            'classifier__C': hp.choice('classifier__C', [10, 100, 1000, 10000]),\n",
    "            'classifier__gamma': hp.choice('classifier__gamma', [0.01, 0.001, 0.0001]),\n",
    "            'classifier__kernel': hp.choice('classifier__kernel', ['poly', 'rbf','sigmoid'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'SVC_IWSmote',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e93d18-ced3-4434-8255-525836529d1b",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c16fbb-54f8-4411-88c2-8eb2ce1910c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', KNeighborsClassifier())])\n",
    "\n",
    "space = {\n",
    "                'classifier__metric': hp.choice('classifier__metric', ['euclidean', 'manhattan','minkowski']),\n",
    "                'classifier__n_neighbors': hp.uniform('classifier__n_neighbors', 10,20)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperopt will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'KNN_IWSmote',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa26c13-050b-49a5-8022-3cf769e2f70f",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e6fbfb-cced-4f60-afeb-6dafcee69ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= BaggingClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'classifier__max_features': hp.quniform('classifier__max_features',10,50,1),\n",
    "            'classifier__bootstrap': hp.choice('classifier__bootstrap', [True, False]),\n",
    "            'classifier__bootstrap_features': hp.choice('classifier__bootstrap_features', [True, False])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'Bagging_IWSmote',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09036f5f-c602-4105-9dd6-c709635f85d0",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993af1fb-b03d-4a88-ab04-2a7559c20302",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= RandomForestClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'max_depth': hp.quniform('max_depth', 1, 30, 1),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            'max_features': hp.uniform('max_features', 0.0001,1),\n",
    "            'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "            'min_samples_split':hp.uniform('min_samples_split',2,6)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'RF_IWSmote',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de87776-892e-4c35-8f1b-0a416ed4a724",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e2b05a-57b1-42f6-b5d4-4b1b6777c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= xgb.XGBClassifier()\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 30, 1),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1),\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 250, 10)),\n",
    "    'min_child_samples': hp.choice('min_child_samples', range(100, 250, 10)),\n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', range(200,10000, 100))\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'XGBoost_IWSmote',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5b4b5b-7072-410b-9c45-7289d886c7e2",
   "metadata": {},
   "source": [
    "## LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896b69f-b36d-4318-a89e-03c6eab629a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= lgb.LGBMClassifier()\n",
    "\n",
    "space = {\n",
    "        'num_leaves': hp.choice('num_leaves',range(20,3000,20)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,15,1)),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0, 1),\n",
    "        'feature_fraction':  hp.uniform('feature_fraction', 0, 1),\n",
    "        'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 0.0005, 0.010),\n",
    "        'lambda_l1': hp.choice('lambda_l1', range(0, 100, 5)),\n",
    "        'lambda_l2': hp.choice('lambda_l2', range(0, 100, 5)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'min_data_in_leaf': hp.choice('min_data_in_leaf', range(200,10000, 100)),\n",
    "        'max_bin': hp.uniform('max_bin', 200, 300),\n",
    "        'min_gain_to_split': hp.uniform('min_gain_to_split', 0,15),\n",
    "        'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss', 'rf'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=50, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata = Comparingdata.append({'Classifier' : 'LightGBM_IWSmote',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dae7cd-df8e-4be8-8f2e-f70ecba00f4a",
   "metadata": {},
   "source": [
    "## Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d18493-e686-4066-9e30-f7b94b466c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table = tabulate(Comparingdata, headers = 'keys', tablefmt = 'html')\n",
    "Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3681cad-c02f-4714-84a4-2e86e4f7bb30",
   "metadata": {},
   "source": [
    "## Visualisations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d35caf5-4b12-41bb-80ce-ca4af8bbcd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualisation = Comparingdata.set_index('Classifier')\n",
    "plt.rcParams['figure.figsize']=[20,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408e09c-73e9-490c-888c-0a6128192d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC_plot = Visualisation.sort_values('MCC', ascending=False).MCC.plot.bar()\n",
    "MCC_plot\n",
    "MCC_plot.figure.savefig(\"MCC_plot.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3420082-d41c-4215-bb28-ea3a676e612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Execution_time_plot = Visualisation.sort_values('Execution_time', ascending=False).Execution_time.plot.barh()\n",
    "Execution_time_plot\n",
    "Execution_time_plot.figure.savefig(\"Execution_time_plot.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0880815-4762-4182-a4ef-6266ae06cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall_plot = Visualisation.sort_values('Recall', ascending=False).Recall.plot.barh()\n",
    "Recall_plot\n",
    "Recall_plot.figure.savefig(\"Recall_plot.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dc972-97e1-46db-a920-7347f4a2b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision_plot = Visualisation.sort_values('Precision', ascending=False).Precision.plot.barh()\n",
    "Precision_plot\n",
    "Precision_plot.figure.savefig(\"Precision_plot.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e4fe3-fb17-48e6-b72d-f1b1072ba832",
   "metadata": {},
   "outputs": [],
   "source": [
    "Balanced_Accuracy_plot = Visualisation.sort_values('Balanced_Accuracy', ascending=False).Balanced_Accuracy.plot.barh()\n",
    "Balanced_Accuracy_plot\n",
    "Balanced_Accuracy_plot.figure.savefig(\"Balanced_Accuracy_plot.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56641220-64eb-43ca-942c-6826d031015a",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922147c2-a963-4b56-9bc1-57e0c02773ee",
   "metadata": {},
   "source": [
    "### Tables for Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56525d69-727f-416d-809e-2c6412575b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExecutionTimes = [['NB', 49.3], ['NB+RUS', 40.1], ['NB+STL', 19099.7], \n",
    "                  ['NB+IW', 19076.6], \n",
    "                  ['KNN', 1686.6], ['KNN+RUS', 1728.5], ['KNN+STL', 23635.2], \n",
    "                  ['KNN+IW', 24752.6],\n",
    "                  ['SVC', 14199.5], ['SVC+RUS', 14450.8], ['SVC+STL', 140446], \n",
    "                  ['SVC+IW', 151178],\n",
    "                  ['DT', 254.1], ['DT+RUS', 323.8], ['DT+STL', 19970.5], \n",
    "                  ['DT+IW', 20253.8],\n",
    "                  ['RF', 1817.5], ['RF+RUS', 3092.62], ['RF+STL', 30567.9], \n",
    "                  ['RF+IW', 30588.3],\n",
    "                  ['BEC', 1361.9], ['BEC+RUS', 2088.47], ['BEC+STL', 27055.7], \n",
    "                  ['BEC+IW', 27205.1],\n",
    "                  ['XGB', 2386.8], ['XGB+RUS', 913.6], ['XGB+STL', 22018.2], \n",
    "                  ['XGB+IW', 21795.5],\n",
    "                  ['LGBM', 200.3], ['LGBM+RUS', 127.5], ['LGBM+STL', 19322.2], \n",
    "                  ['LGBM+IW', 19285.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc795344-79c1-400c-9f1e-c2e81026a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExecutionTimesTable = pd.DataFrame(\n",
    "    ExecutionTimes, columns=['Model', 'Execution time in seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db391e4-3ae9-478a-acb5-bab08a024fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExecutionTimesTable = ExecutionTimesTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ead14-092a-49ca-a18c-f5c837c918c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[11,2]\n",
    "ExecutionTimesViz = ExecutionTimesTable.sort_values('Execution time in seconds', ascending=False).plot.bar(width=0.9, color='green')\n",
    "plt.title('Model Execution Time Plot in Descending Order')\n",
    "plt.xlabel(None)\n",
    "for label in (ExecutionTimesViz.get_xticklabels() + ExecutionTimesViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "ExecutionTimesViz.figure.savefig('Model_Execution_Time_Plot.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e722d8-8a34-4dec-86ed-1e3c84831c83",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44bc2ca-e31c-4488-8211-f98e9bb719eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy =       [['NB', 0.694], ['NB+RUS', 0.678], ['NB+STL', 0.641], \n",
    "                  ['NB+IW', 0.969], \n",
    "                  ['KNN', 0.773], ['KNN+RUS', 0.773], ['KNN+STL', 0.773], \n",
    "                  ['KNN+IW', 0.773],\n",
    "                  ['SVC', 0.780], ['SVC+RUS', 0.780], ['SVC+STL', 0.780], \n",
    "                  ['SVC+IW', 0.780],\n",
    "                  ['DT', 0.728], ['DT+RUS', 0.726], ['DT+STL', 0.727], \n",
    "                  ['DT+IW', 0.727],\n",
    "                  ['RF', 0.806], ['RF+RUS', 0.805], ['RF+STL', 0.806], \n",
    "                  ['RF+IW', 0.805],\n",
    "                  ['BEC', 0.787], ['BEC+RUS', 0.786], ['BEC+STL', 0.789], \n",
    "                  ['BEC+IW', 0.786],\n",
    "                  ['XGB', 0.800], ['XGB+RUS', 0.800], ['XGB+STL', 0.800], \n",
    "                  ['XGB+IW', 0.800],\n",
    "                  ['LGBM', 0.808], ['LGBM+RUS', 0.738], ['LGBM+STL', 0.805], \n",
    "                  ['LGBM+IW', 0.835]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd63c86-e824-49a1-8491-13b96fa4b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AccuracyTable = pd.DataFrame(\n",
    "    Accuracy, columns=['Model', 'Values'])\n",
    "AccuracyTable = AccuracyTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00cf4f2-7afd-4f58-b678-d3d6ffe5f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "AccuracyViz = AccuracyTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('Accuracy Values in Descending Order')\n",
    "plt.xlabel(None)\n",
    "for label in (AccuracyViz.get_xticklabels() + AccuracyViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "AccuracyViz.figure.savefig('Accuracy_Plot.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd80c7-f974-46c0-98d7-20153ba58cd5",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162b845-08b6-4c11-8ab5-75c04f22be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Balanced_Accuracy = [['NB', 0.730], ['NB+RUS', 0.725], ['NB+STL', 0.710], \n",
    "                  ['NB+IW', 0.730], \n",
    "                  ['KNN', 0.654], ['KNN+RUS', 0.654], ['KNN+STL', 0.654], \n",
    "                  ['KNN+IW', 0.654],\n",
    "                  ['SVC', 0.577], ['SVC+RUS', 0.577], ['SVC+STL', 0.577], \n",
    "                  ['SVC+IW', 0.577],\n",
    "                  ['DT', 0.640], ['DT+RUS', 0.638], ['DT+STL', 0.638], \n",
    "                  ['DT+IW', 0.641],\n",
    "                  ['RF', 0.672], ['RF+RUS', 0.673], ['RF+STL', 0.673], \n",
    "                  ['RF+IW', 0.672],\n",
    "                  ['BEC', 0.650], ['BEC+RUS', 0.648], ['BEC+STL', 0.651], \n",
    "                  ['BEC+IW', 0.648],\n",
    "                  ['XGB', 0.683], ['XGB+RUS', 0.683], ['XGB+STL', 0.683], \n",
    "                  ['XGB+IW', 0.683],\n",
    "                  ['LGBM', 0.688], ['LGBM+RUS', 0.750], ['LGBM+STL', 0.697], \n",
    "                  ['LGBM+IW', 0.725]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74b8f5-4b1d-4546-a02c-931160df97d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Balanced_AccuracyTable = pd.DataFrame(\n",
    "    Balanced_Accuracy, columns=['Model', 'Values'])\n",
    "Balanced_AccuracyTable = Balanced_AccuracyTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b16d20-13ba-40f8-a8c2-2a4cfc3b755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "Balanced_AccuracyViz = Balanced_AccuracyTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('Balanced_Accuracy Values in Descending Order')\n",
    "plt.xlabel(None)\n",
    "for label in (Balanced_AccuracyViz.get_xticklabels() + Balanced_AccuracyViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "Balanced_AccuracyViz.figure.savefig('Balanced__Plot.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264027e-306b-4c0b-9bdf-ec424ee0c5a6",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99dde9f-992a-4f94-b6bb-c92f08a6e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision = [['NB', 0.434], ['NB+RUS', 0.421], ['NB+STL', 0.394], \n",
    "                  ['NB+IW', 0.436], \n",
    "                  ['KNN', 0.551], ['KNN+RUS', 0.551], ['KNN+STL', 0.551], \n",
    "                  ['KNN+IW', 0.551],\n",
    "                  ['SVC', 0.717], ['SVC+RUS', 0.717], ['SVC+STL', 0.717], \n",
    "                  ['SVC+IW', 0.717],\n",
    "                  ['DT', 0.449], ['DT+RUS', 0.447], ['DT+STL', 0.447], \n",
    "                  ['DT+IW', 0.449],\n",
    "                  ['RF', 0.674], ['RF+RUS', 0.670], ['RF+STL', 0.676], \n",
    "                  ['RF+IW', 0.672],\n",
    "                  ['BEC', 0.608], ['BEC+RUS', 0.607], ['BEC+STL', 0.615], \n",
    "                  ['BEC+IW', 0.607],\n",
    "                  ['XGB', 0.634], ['XGB+RUS', 0.634], ['XGB+STL', 0.634], \n",
    "                  ['XGB+IW', 0.634],\n",
    "                  ['LGBM', 0.660], ['LGBM+RUS', 0.480], ['LGBM+STL', 0.636], \n",
    "                  ['LGBM+IW', 0.734]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7955b-33a8-498c-8286-62a257b8a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PrecisionTable = pd.DataFrame(\n",
    "    Precision, columns=['Model', 'Values'])\n",
    "PrecisionTable = PrecisionTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceeb4f4-c499-4d36-866d-b656e7058f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "PrecisionViz = PrecisionTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('Precision Values in Descending Order')\n",
    "plt.xlabel(None)\n",
    "for label in (PrecisionViz.get_xticklabels() + PrecisionViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "PrecisionViz.figure.savefig('Precision_Plot.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960e2c7-187c-4da0-aeb4-479cc813fbed",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df0a34-a9ed-4921-8c3e-a94f22fb2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall = [['NB', 0.799], ['NB+RUS', 0.818], ['NB+STL', 0.848], \n",
    "                  ['NB+IW', 0.798], \n",
    "                  ['KNN', 0.419], ['KNN+RUS', 0.419], ['KNN+STL', 0.419], \n",
    "                  ['KNN+IW', 0.419],\n",
    "                  ['SVC', 0.176], ['SVC+RUS', 0.176], ['SVC+STL', 0.176], \n",
    "                  ['SVC+IW', 0.176],\n",
    "                  ['DT', 0.467], ['DT+RUS', 0.465], ['DT+STL', 0.464], \n",
    "                  ['DT+IW', 0.470],\n",
    "                  ['RF', 0.409], ['RF+RUS', 0.412], ['RF+STL', 0.411], \n",
    "                  ['RF+IW', 0.409],\n",
    "                  ['BEC', 0.380], ['BEC+RUS', 0.376], ['BEC+STL', 0.380], \n",
    "                  ['BEC+IW', 0.375],\n",
    "                  ['XGB', 0.450], ['XGB+RUS', 0.450], ['XGB+STL', 0.450], \n",
    "                  ['XGB+IW', 0.450],\n",
    "                  ['LGBM', 0.453], ['LGBM+RUS', 0.775], ['LGBM+STL', 0.484], \n",
    "                  ['LGBM+IW', 0.510]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256bbd91-eaf4-451b-85e8-6b0eb6c6fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RecallTable = pd.DataFrame(\n",
    "    Recall, columns=['Model', 'Values'])\n",
    "RecallTable = RecallTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f11fe-f01f-471f-a3cb-dd83933bf8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "RecallViz = RecallTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('Recall Values in Descending Order')\n",
    "plt.xlabel(None)\n",
    "for label in (RecallViz.get_xticklabels() + RecallViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "RecallViz.figure.savefig('Recall_Plot.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f488a19-0544-468d-9f66-f4292164d35d",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae28f7d-8b79-498b-a6cf-43b7050b5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC = [['NB', 0.397], ['NB+RUS', 0.388], ['NB+STL', 0.363], \n",
    "                  ['NB+IW', 0.399], \n",
    "                  ['KNN', 0.340], ['KNN+RUS', 0.339], ['KNN+STL', 0.340], \n",
    "                  ['KNN+IW', 0.339],\n",
    "                  ['SVC', 0.277], ['SVC+RUS', 0.277], ['SVC+STL', 0.277], \n",
    "                  ['SVC+IW', 0.277],\n",
    "                  ['DT', 0.276], ['DT+RUS', 0.273], ['DT+STL', 0.273], \n",
    "                  ['DT+IW', 0.277],\n",
    "                  ['RF', 0.416], ['RF+RUS', 0.415], ['RF+STL', 0.418], \n",
    "                  ['RF+IW', 0.415],\n",
    "                  ['BEC', 0.358], ['BEC+RUS', 0.355], ['BEC+STL', 0.362], \n",
    "                  ['BEC+IW', 0.355],\n",
    "                  ['XGB', 0.414], ['XGB+RUS', 0.414], ['XGB+STL', 0.414], \n",
    "                  ['XGB+IW', 0.414],\n",
    "                  ['LGBM', 0.433], ['LGBM+RUS', 0.441], ['LGBM+STL', 0.434], \n",
    "                  ['LGBM+IW', 0.517]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a3973-40c0-4d4d-a66b-3a7a0c439bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCCTable = pd.DataFrame(\n",
    "    MCC, columns=['Model', 'Values'])\n",
    "MCCTable = MCCTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507821d9-d736-45d3-aef8-6b5c8b2cf951",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "MCCViz = MCCTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('MCC Values in Descending Order')\n",
    "plt.xlabel(None)\n",
    "for label in (MCCViz.get_xticklabels() + MCCViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "MCCViz.figure.savefig('MCC_Plot.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27982d35-93ae-4288-bfc7-fdd66932b43b",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884cd3f-6e5f-49d9-a8fc-b9c640b4714d",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9643508-c91f-4eae-8028-4dd9381aab2b",
   "metadata": {},
   "source": [
    "# Highly imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c867ab0-a51b-429b-994f-2b368f7179c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_imbalanced_df = imputted_data.drop(imputted_data.query('default_ind == 1').sample(n=19087).index)\n",
    "highly_imbalanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f3d53a-d647-450f-9adb-495f765e11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts_imbalanced = highly_imbalanced_df.default_ind.value_counts()\n",
    "print(val_counts_imbalanced)\n",
    "\n",
    "print('---------------------------------------')\n",
    "print('No Frauds', round(highly_imbalanced_df['default_ind'].value_counts()[0]/len(highly_imbalanced_df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(highly_imbalanced_df['default_ind'].value_counts()[1]/len(highly_imbalanced_df) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade8fda-5e2f-41b4-b5eb-af43dda7c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X = highly_imbalanced_df.drop('default_ind', axis=1)\n",
    "y = highly_imbalanced_df['default_ind']\n",
    "\n",
    "original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(\n",
    "X, y, test_size=0.33, random_state=42, shuffle=True, stratify=y)  \n",
    "    \n",
    "# Turn into an array\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "# See if both the train and test label distribution are similarly distributed\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(original_ytrain))\n",
    "print(test_counts_label/ len(original_ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c93b1b-6797-48fb-beb6-b84b788177ee",
   "metadata": {},
   "source": [
    "# HyperOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c8e006-a801-41c3-abb6-c573cc9602c2",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e10380-93f0-41fd-a7ac-2302758ea285",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', GaussianNB())])\n",
    "\n",
    "space = {\n",
    "    'classifier__var_smoothing': hp.quniform('classifier__var_smoothing',0,1,0.0001)\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'NB_HyperOpt_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57a500-6a3f-40cb-aff5-8aeb8e760e13",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408de0b3-cde6-4b3c-9b5b-4dc915e130dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= DecisionTreeClassifier()\n",
    "\n",
    "space = {\n",
    "                  'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "                  'max_depth': hp.quniform('max_depth', 3,15,1),\n",
    "                  'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "                  'min_samples_leaf': hp.uniform('min_samples_leaf',1,5),\n",
    "                  'min_samples_split': hp.uniform('min_samples_split',1,8)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "print('Best parameters: {}'.format(best_param))\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'DT_HyperOpt_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3de0d6-5f17-4957-a6c5-258e7d689362",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92967590-ed1b-49fe-b7a9-0e001987e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', SVC())])\n",
    "\n",
    "space = {\n",
    "                 \n",
    "            'classifier__C': hp.choice('classifier__C', [10, 100, 1000, 10000]),\n",
    "            'classifier__gamma': hp.choice('classifier__gamma', [0.01, 0.001, 0.0001]),\n",
    "            'classifier__kernel': hp.choice('classifier__kernel', ['poly', 'rbf','sigmoid'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'SVC_HyperOpt_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294ef8c-ca3f-4822-a512-addea76152db",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db1fed-9458-443c-a654-f4afc1542de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', KNeighborsClassifier())])\n",
    "\n",
    "space = {\n",
    "                'classifier__metric': hp.choice('classifier__metric', ['euclidean', 'manhattan','minkowski']),\n",
    "                'classifier__n_neighbors': hp.uniform('classifier__n_neighbors', 10,20)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperopt will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'KNN_HyperOpt_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79fc42-429f-40bc-97ca-05d5a50b6878",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34976316-2aeb-42b8-b27a-b6d808011d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= BaggingClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'classifier__max_features': hp.quniform('classifier__max_features',10,50,1),\n",
    "            'classifier__bootstrap': hp.choice('classifier__bootstrap', [True, False]),\n",
    "            'classifier__bootstrap_features': hp.choice('classifier__bootstrap_features', [True, False])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI= Comparingdata_HI.append({'Classifier' : 'Bagging_HyperOpt_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9fecc8-dffb-4c6a-ba24-c9de5e0f15c8",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed5af1-c6f0-46f8-b4bf-7488372dbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= RandomForestClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "            'max_depth': hp.quniform('max_depth', 1, 45, 1),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            'max_features': hp.uniform('max_features', 0.0001,1),\n",
    "            'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "            'min_samples_split':hp.uniform('min_samples_split',2,6)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'RF_HyperOpt_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7514ea1e-44ee-4a0e-a4dc-2a66cc0fb4f6",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13951b5-c78e-4caf-b9f7-9d3583567fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= xgb.XGBClassifier()\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 45, 1),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1),\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 250, 10)),\n",
    "    'min_child_samples': hp.choice('min_child_samples', range(100, 250, 10)),\n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', range(200,10000, 100))\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'XGBoost_HyperOpt_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b23b24-b3f4-43be-b897-41936ab8e17c",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b96649-15bf-4d9c-aabf-2d2aef3a5309",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= lgb.LGBMClassifier()\n",
    "\n",
    "space = {\n",
    "        'num_leaves': hp.choice('num_leaves',range(1,1000,1)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,45,1)),\n",
    "        'lambda_l1': hp.choice('lambda_l1', range(0, 100, 5)),\n",
    "        'lambda_l2': hp.choice('lambda_l2', range(0, 100, 5)),\n",
    "        'learning_rate': hp.quniform('learning_rate', 0, 0.5, 0.001),\n",
    "        'min_data_in_leaf': hp.choice('min_data_in_leaf', range(200,10000, 100)),\n",
    "        'max_bin': hp.uniform('max_bin', 200, 300),\n",
    "        'min_gain_to_split': hp.uniform('min_gain_to_split', 0,15),\n",
    "        'n_estimators': hp.choice('n_estimators', range(100,10000, 100)),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss', 'rf'])\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=objective, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'LightGBM_HyperOpt_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24212525-cec7-4c49-8608-3499681edcb0",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed04766-8e82-4e11-8f6f-70a51d574730",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b455a1-44b9-451f-a5e3-f2c0b844c6bd",
   "metadata": {},
   "source": [
    "## Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac863ce-eea9-49e7-9887-424530bbb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total =0\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        sampling=RandomUnderSampler()\n",
    "        X_sampling, y_sampling = sampling.fit_resample(X_train, y_train)\n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        s=pipe.score(X_test, y_test)\n",
    "        total= total + s\n",
    "    score = total/5            \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496d56a-8542-4c3c-91d9-5e17d527cc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "def score_resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total_accuracy =np.array([])\n",
    "    total_balanced_accuracy =np.array([])\n",
    "    total_precision =np.array([])\n",
    "    total_recall =np.array([])\n",
    "    total_MCC =np.array([])\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        sampling=RandomUnderSampler()\n",
    "        X_sampling, y_sampling = sampling.fit_resample(X_train, y_train)\n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Calculation\n",
    "        test_accuracy=accuracy_score(y_test, y_pred)\n",
    "        test_balanced_accuracy=balanced_accuracy_score(y_test, y_pred)\n",
    "        test_precision=precision_score(y_test, y_pred)\n",
    "        test_recall=recall_score(y_test, y_pred)\n",
    "        test_MCC=matthews_corrcoef(y_test, y_pred)\n",
    "        \n",
    "        total_accuracy =np.append(total_accuracy ,np.array([test_accuracy]), axis=0)\n",
    "        total_balanced_accuracy =np.append(total_balanced_accuracy ,np.array([test_balanced_accuracy]), axis=0)\n",
    "        total_precision =np.append(total_precision ,np.array([test_precision]), axis=0)\n",
    "        total_recall =np.append(total_recall ,np.array([test_recall]), axis=0)\n",
    "        total_MCC =np.append(total_MCC ,np.array([test_MCC]), axis=0)\n",
    "           \n",
    "    metrics = {}\n",
    "    metrics['test_accuracy']= total_accuracy\n",
    "    metrics['test_balanced_accuracy']=total_balanced_accuracy\n",
    "    metrics['test_precision']=total_precision\n",
    "    metrics['test_recall']=total_recall\n",
    "    metrics['test_MCC']=total_MCC\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e9d3b-80d2-41fe-a855-59375bf9432f",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951ee0e-e688-4a9b-aebd-ebbc405948ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', GaussianNB())])\n",
    "\n",
    "space = {\n",
    "'classifier__var_smoothing': hp.quniform('classifier__var_smoothing',0,1,0.0001)}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'NB_RUS_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f19ec2-1c8c-45e7-8abd-b925a63e166d",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f5324-d82f-47a8-b833-9a4fe8a6a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= DecisionTreeClassifier()\n",
    "\n",
    "space = {\n",
    "                  'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "                  'max_depth': hp.quniform('max_depth', 1,30,2),\n",
    "                  'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "                  'min_samples_leaf': hp.uniform('min_samples_leaf',1,5),\n",
    "                  'min_samples_split': hp.uniform('min_samples_split',1,8)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "print('Best parameters: {}'.format(best_param))\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI= Comparingdata_HI.append({'Classifier' : 'DT_RUS_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c735f6-9e77-4713-97e4-136d57509b31",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31d3f5-15f5-4e33-9140-e4d801017258",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', SVC())])\n",
    "\n",
    "space = {\n",
    "                 \n",
    "            'classifier__C': hp.choice('classifier__C', [10, 100, 1000, 10000]),\n",
    "            'classifier__gamma': hp.choice('classifier__gamma', [0.01, 0.001, 0.0001]),\n",
    "            'classifier__kernel': hp.choice('classifier__kernel', ['poly', 'rbf','sigmoid'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'SVC_RUS_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca92e24-274a-40c4-9527-deddf865afb5",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0573b-3ac5-41fd-98fa-91c3c8f473ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', KNeighborsClassifier())])\n",
    "\n",
    "space = {\n",
    "                'classifier__metric': hp.choice('classifier__metric', ['euclidean', 'manhattan','minkowski']),\n",
    "                'classifier__n_neighbors': hp.uniform('classifier__n_neighbors', 10,20)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperopt will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'KNN_RUS_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d384ec27-082e-40cf-aa54-9f234f01ee2b",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930ac046-1a78-4c80-b278-04f575adc03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= BaggingClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 200)),\n",
    "            'classifier__max_features': hp.quniform('classifier__max_features',10,50,2),\n",
    "            'classifier__bootstrap': hp.choice('classifier__bootstrap', [True, False]),\n",
    "            'classifier__bootstrap_features': hp.choice('classifier__bootstrap_features', [True, False])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'Bagging_RUS_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac370e0e-dac1-487c-96e4-152f329ba977",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98acb2-7d79-4e4a-a162-43a3b8a3689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= RandomForestClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 200)),\n",
    "            'max_depth': hp.quniform('max_depth', 1, 30, 2),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            'max_features': hp.uniform('max_features', 0.0001,1),\n",
    "            'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "            'min_samples_split':hp.uniform('min_samples_split',2,6)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'RF_RUS_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4639b-b927-4d55-9a87-a82ee400bd9e",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1228cad-2215-4827-abee-1e6b47ba4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= xgb.XGBClassifier()\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 30, 2),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1),\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 250, 20)),\n",
    "    'min_child_samples': hp.choice('min_child_samples', range(100, 250, 20)),\n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', range(200,10000, 200))\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'XGBoost_RUS_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096cc18-c342-4701-b4d1-ef1ec211bc75",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92f751-4937-4a9b-ab56-3be62df18528",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= lgb.LGBMClassifier()\n",
    "\n",
    "space = {\n",
    "        'num_leaves': hp.choice('num_leaves',range(20,3000,20)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,30,2)),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0, 1),\n",
    "        'feature_fraction':  hp.uniform('feature_fraction', 0, 1),\n",
    "        'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 0.0005, 0.010),\n",
    "        'lambda_l1': hp.choice('lambda_l1', range(0, 100, 5)),\n",
    "        'lambda_l2': hp.choice('lambda_l2', range(0, 100, 5)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'min_data_in_leaf': hp.choice('min_data_in_leaf', range(200,10000, 200)),\n",
    "        'max_bin': hp.uniform('max_bin', 200, 300),\n",
    "        'min_gain_to_split': hp.uniform('min_gain_to_split', 0,15),\n",
    "        'n_estimators': hp.choice('n_estimators', range(200,10000, 200)),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss', 'rf'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI= Comparingdata_HI.append({'Classifier' : 'LightGBM_RUS_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43aeb19-892f-4bee-9e0e-c97f4b438e19",
   "metadata": {},
   "source": [
    "## SMOTE & TomekLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5484a5b-ee58-4097-8e45-85c472d68826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total =0\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        sampling=SMOTETomek(tomek=TomekLinks())\n",
    "        X_sampling, y_sampling = sampling.fit_resample(X_train, y_train)\n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        s=pipe.score(X_test, y_test)\n",
    "        total= total + s\n",
    "    score = total/5            \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ce36f-5d94-4a86-9c40-678674ec902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "def score_resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total_accuracy =np.array([])\n",
    "    total_balanced_accuracy =np.array([])\n",
    "    total_precision =np.array([])\n",
    "    total_recall =np.array([])\n",
    "    total_MCC =np.array([])\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        sampling=SMOTETomek(tomek=TomekLinks())\n",
    "        X_sampling, y_sampling = sampling.fit_resample(X_train, y_train)\n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Calculation\n",
    "        test_accuracy=accuracy_score(y_test, y_pred)\n",
    "        test_balanced_accuracy=balanced_accuracy_score(y_test, y_pred)\n",
    "        test_precision=precision_score(y_test, y_pred)\n",
    "        test_recall=recall_score(y_test, y_pred)\n",
    "        test_MCC=matthews_corrcoef(y_test, y_pred)\n",
    "        \n",
    "        total_accuracy =np.append(total_accuracy ,np.array([test_accuracy]), axis=0)\n",
    "        total_balanced_accuracy =np.append(total_balanced_accuracy ,np.array([test_balanced_accuracy]), axis=0)\n",
    "        total_precision =np.append(total_precision ,np.array([test_precision]), axis=0)\n",
    "        total_recall =np.append(total_recall ,np.array([test_recall]), axis=0)\n",
    "        total_MCC =np.append(total_MCC ,np.array([test_MCC]), axis=0)\n",
    "           \n",
    "    metrics = {}\n",
    "    metrics['test_accuracy']= total_accuracy\n",
    "    metrics['test_balanced_accuracy']=total_balanced_accuracy\n",
    "    metrics['test_precision']=total_precision\n",
    "    metrics['test_recall']=total_recall\n",
    "    metrics['test_MCC']=total_MCC\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d1a7f-3e33-4a76-a426-527190b14c3d",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec327c74-8a8f-4ba7-b76c-fc6c7bd347a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', GaussianNB())])\n",
    "\n",
    "space = {\n",
    "        'classifier__var_smoothing': hp.quniform('classifier__var_smoothing',0,1,0.0001)}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'NB_SmoteTomek_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0eb47-4666-4fcf-9900-ee37ee8df2bf",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84bba0-58e0-49d8-b5d2-8d93336bb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= DecisionTreeClassifier()\n",
    "\n",
    "space = {\n",
    "                  'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "                  'max_depth': hp.quniform('max_depth', 1,30,2),\n",
    "                  'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "                  'min_samples_leaf': hp.uniform('min_samples_leaf',1,5),\n",
    "                  'min_samples_split': hp.uniform('min_samples_split',1,8)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "print('Best parameters: {}'.format(best_param))\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'DT_SmoteTomek_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac5e49-2beb-4db7-9077-14b3c2d79a86",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f73250-2efc-4f5c-9166-5c3e64a74cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', SVC())])\n",
    "\n",
    "space = {\n",
    "                 \n",
    "            'classifier__C': hp.choice('classifier__C', [10, 100, 1000, 10000]),\n",
    "            'classifier__gamma': hp.choice('classifier__gamma', [0.01, 0.001, 0.0001]),\n",
    "            'classifier__kernel': hp.choice('classifier__kernel', ['poly', 'rbf','sigmoid'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'SVC_SmoteTomek_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c2233-3e03-4faf-8271-5a8d290bf574",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28813d-97bf-4235-a155-5c8a7272548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', KNeighborsClassifier())])\n",
    "\n",
    "space = {\n",
    "                'classifier__metric': hp.choice('classifier__metric', ['euclidean', 'manhattan','minkowski']),\n",
    "                'classifier__n_neighbors': hp.uniform('classifier__n_neighbors', 10,20)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperopt will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'KNN_SmoteTomek_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c95c967-4037-439a-937a-f228b64c1839",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525df701-595f-4270-b982-0ef400e1d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= BaggingClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 200)),\n",
    "            'classifier__max_features': hp.quniform('classifier__max_features',10,50,2),\n",
    "            'classifier__bootstrap': hp.choice('classifier__bootstrap', [True, False]),\n",
    "            'classifier__bootstrap_features': hp.choice('classifier__bootstrap_features', [True, False])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'Bagging_SmoteTomek_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e768ee-e7ee-4b23-9578-1facf7e1aceb",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d3d6b-ee46-45f9-a469-d3b346709f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= RandomForestClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 200)),\n",
    "            'max_depth': hp.quniform('max_depth', 1, 30, 2),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            'max_features': hp.uniform('max_features', 0.0001,1),\n",
    "            'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "            'min_samples_split':hp.uniform('min_samples_split',2,6)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'RF_SmoteTomek_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b4b9f7-2ae5-4646-ae8b-45838359b0a8",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126412e0-a77f-4758-9db0-4ceb8701e615",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= xgb.XGBClassifier()\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 30, 2),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1),\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 250, 20)),\n",
    "    'min_child_samples': hp.choice('min_child_samples', range(100, 250, 20)),\n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', range(200,10000, 200))\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'XGBoost_SmoteTomek_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf57b01-0fb1-4c0e-9b94-370798fbafff",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25200c-08f8-4b30-a17c-72474c45c9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= lgb.LGBMClassifier()\n",
    "\n",
    "space = {\n",
    "        'num_leaves': hp.choice('num_leaves',range(20,3000,20)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,30,1)),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0, 1),\n",
    "        'feature_fraction':  hp.uniform('feature_fraction', 0, 1),\n",
    "        'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 0.0005, 0.010),\n",
    "        'lambda_l1': hp.choice('lambda_l1', range(0, 100, 5)),\n",
    "        'lambda_l2': hp.choice('lambda_l2', range(0, 100, 5)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'min_data_in_leaf': hp.choice('min_data_in_leaf', range(200,10000, 100)),\n",
    "        'max_bin': hp.uniform('max_bin', 200, 300),\n",
    "        'min_gain_to_split': hp.uniform('min_gain_to_split', 0,15),\n",
    "        'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss', 'rf'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'LightGBM_SmoteTomek_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f46c5-4f94-490c-9aca-95e411417751",
   "metadata": {},
   "source": [
    "## IW-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6a335-e438-45c3-b948-2e8303dfa099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classfication and regression tree\n",
    "def CART(X=original_Xtrain, y=original_ytrain, XX=original_Xtest):\n",
    "    model = DecisionTreeClassifier()\n",
    "    model.fit(X, y)\n",
    "    predicted = model.predict(XX)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "class IW_SMOTE():\n",
    "    def __init__(self, data, target, balance=1):\n",
    "        self.balance = balance;  # Sampling rate\n",
    "        self.data = original_Xtrain # The training set\n",
    "        self.target = original_ytrain # The labels of training set\n",
    "\n",
    "    \"\"\"\n",
    "            :param lamda: lamda*imbalance ratio = the number of cart\n",
    "            :param thres: The threshold of filtering noise\n",
    "            :param k_neighbor: k nearest neighbor\n",
    "            :param divide_times: The ratio of under sampling minority samples\n",
    "            :param gen_times: The ratio of generated minority class to majority class samples\n",
    "            :return: The synthetic samples, attributes and labels\n",
    "    \"\"\"\n",
    "    def IW_SMOTE(self, lamda=100, thres=0.5, divide_times=2, gen_times=1, k_neighbor=5):\n",
    "        # x_x:Temporary variable, save the training set\n",
    "        x_x = pd.DataFrame(self.data)\n",
    "        x_x[len(x_x.columns)] = self.target\n",
    "        m, n = len(x_x), len(x_x.columns) #m: the number of trainning set; n: the number of columns of the trainning set\n",
    "        z = x_x[x_x[n - 1] == 1]  # acquire the minority set\n",
    "        p = x_x[x_x[n - 1] == -1]  # acquire the majority set\n",
    "        m1, n1 = len(z), len(z.columns) # m1: the number of minority samples; n1: the number of columns of the minority samples\n",
    "        m2, n2 = len(p), len(p.columns) # m2: the number of majority samples; n2: the number of columns of the majority samples\n",
    "        IR = m2 / m1  # imbalance ratio\n",
    "        predict_min_labelset = pd.DataFrame(columns = range(int(IR * lamda))) # the predicted labels of the minority samples\n",
    "        predict_maj_labelset = pd.DataFrame(columns = range(int(IR * lamda))) # the predicted labels of the majority samples\n",
    "        # train under-bagging CART\n",
    "        for i_1 in range(int(IR * lamda)):\n",
    "            train_subset = z.sample(int(m1 / divide_times)) # train_subset: the subset of training set\n",
    "            train_subset = train_subset.append(p.sample(int(m1 / divide_times), replace=True))\n",
    "            predict_maj_labelset[i_1] = CART(np.array(train_subset.iloc[:, 0:n1 - 1]), np.array(train_subset[n1 - 1]),\n",
    "                                             np.array(p.iloc[:, 0:n2 - 1]))\n",
    "            predict_min_labelset[i_1] = CART(np.array(train_subset.iloc[:, 0:n1 - 1]), np.array(train_subset[n1 - 1]),\n",
    "                                             np.array(z.iloc[:, 0:n1 - 1]))\n",
    "        # filterring noise\n",
    "        err_rate_min = []  # record the error rate of the reserved minority instance\n",
    "        reserve_min = []  # record the reserved minority instances\n",
    "        num_reserve_min = 0  # the number of minority samples after denoising\n",
    "        z1 = np.array(z)\n",
    "        predict_min_labelset = np.array(predict_min_labelset)\n",
    "        for i_2 in range(m1):\n",
    "            num_right = 0  # record the number of instance which is predicted accurately\n",
    "            for j in range(int(IR * lamda)):\n",
    "                if predict_min_labelset[i_2][j] == z1[i_2][n1 - 1]:\n",
    "                    num_right = num_right + 1\n",
    "            if ((int(IR * lamda) - num_right) / int(IR * lamda) < thres):\n",
    "                num_reserve_min += 1\n",
    "                reserve_min.append(z1[i_2])\n",
    "                if (int(IR * lamda) - num_right) / int(IR * lamda) < 1 / int(IR * lamda):\n",
    "                    err_rate_min.append(1 / int(IR * lamda))\n",
    "                else:\n",
    "                    err_rate_min.append((int(IR * lamda) - num_right) / int(IR * lamda))\n",
    "        reserve_min = pd.DataFrame(reserve_min)\n",
    "        err_rate_min = pd.DataFrame(err_rate_min)\n",
    "        err_rate_maj = []  # record the error rate of the reserved minority instance\n",
    "        reserve_maj = []  # record the reserved minority instances\n",
    "        num_reserve_maj = 0  # the number of majority samples after denoising\n",
    "        p1 = np.array(p)\n",
    "        predict_maj_labelset = np.array(predict_maj_labelset)\n",
    "        for i_3 in range(m2):\n",
    "            num_right = 0  # record the number of instance which is predicted accurately\n",
    "            for j in range(int(IR * lamda)):\n",
    "                if predict_maj_labelset[i_3][j] == p1[i_3][n2 - 1]:\n",
    "                    num_right = num_right + 1\n",
    "            if ((int(IR * lamda) - num_right) / int(IR * lamda) < thres):\n",
    "                num_reserve_maj += 1\n",
    "                reserve_maj.append(p1[i_3])\n",
    "                if (int(IR * lamda) - num_right) / int(IR * lamda) < 1 / int(IR * lamda):\n",
    "                    err_rate_maj.append(1 / int(IR * lamda))\n",
    "                else:\n",
    "                    err_rate_maj.append((int(IR * lamda) - num_right) / int(IR * lamda))\n",
    "        reserve_maj = pd.DataFrame(reserve_maj)\n",
    "\n",
    "        # generate the synthetic minority instances\n",
    "        weight = err_rate_min[0] / sum(err_rate_min[0])  # Record the importance of each sample\n",
    "        num_need_generate = gen_times * num_reserve_maj - num_reserve_min  # The number of minority samples that need to be synthesized\n",
    "        if num_need_generate == num_reserve_maj:\n",
    "            return np.array(reserve_maj.iloc[:, 0:len(reserve_maj.columns) - 1]), np.array(\n",
    "                reserve_maj[len(reserve_maj.columns) - 1])\n",
    "        else:\n",
    "            num_generate = 0 # the number of be generated\n",
    "            new_set = pd.DataFrame(columns=range(n1))\n",
    "            for i_4 in range(num_reserve_min):\n",
    "                reserve_min_1 = reserve_min\n",
    "                nums = pd.DataFrame(weight * (gen_times * num_reserve_maj - num_reserve_min)).iloc[i_4, 0]\n",
    "                reserve_min_1 = np.array(reserve_min_1)\n",
    "                dis = [0] * num_reserve_min # distance matrix of per sample\n",
    "                for m in range(num_reserve_min):\n",
    "                    dis[m] = np.linalg.norm(reserve_min_1[i_4] - reserve_min_1[m])\n",
    "                b = sorted(enumerate(dis), key=lambda xxx: xxx[1]) #Sorted dis\n",
    "                b = b[1:k_neighbor + 1] # choice knn\n",
    "                for j in range(int(nums)):\n",
    "                    num_generate = num_generate + 1\n",
    "                    s_b = random.choice(b)\n",
    "                    select_ins = reserve_min.iloc[s_b[0], :]\n",
    "                    new_ins = (reserve_min.iloc[i_4, :] - pd.DataFrame(select_ins).T) * random.random() + pd.DataFrame(\n",
    "                        select_ins).T  # generate funtion\n",
    "                    new_set = new_set.append(pd.DataFrame(new_ins))  # add the new instance into a temporary set\n",
    "            new_z = reserve_min.append(new_set) # The minority synthetic samples\n",
    "            new_original_data = reserve_maj.append(new_z) # The synthetic samples\n",
    "            new_original_data.index = range(len(new_original_data))\n",
    "            # Returns an oversampled dataset\n",
    "            return np.array(new_original_data.iloc[:, 0:len(new_original_data.columns) - 1]), np.array(new_original_data[len(new_original_data.columns) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf1fa48-6896-4de0-8efc-21ea09d74fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_resamplingCV(params, X=original_Xtrain, y=original_ytrain, n_jobs=-1):\n",
    "    \n",
    "    skf = StratifiedKFold(shuffle=True)\n",
    "    total_accuracy =np.array([])\n",
    "    total_balanced_accuracy =np.array([])\n",
    "    total_precision =np.array([])\n",
    "    total_recall =np.array([])\n",
    "    total_MCC =np.array([])\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_sampling =IW_SMOTE(X_train, y_train).data\n",
    "        y_sampling =IW_SMOTE(X_train, y_train).target \n",
    "        \n",
    "        pipe.fit(X_sampling, y_sampling)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        \n",
    "        # Calculation\n",
    "        test_accuracy=accuracy_score(y_test, y_pred)\n",
    "        test_balanced_accuracy=balanced_accuracy_score(y_test, y_pred)\n",
    "        test_precision=precision_score(y_test, y_pred)\n",
    "        test_recall=recall_score(y_test, y_pred)\n",
    "        test_MCC=matthews_corrcoef(y_test, y_pred)\n",
    "        \n",
    "        total_accuracy =np.append(total_accuracy ,np.array([test_accuracy]), axis=0)\n",
    "        total_balanced_accuracy =np.append(total_balanced_accuracy ,np.array([test_balanced_accuracy]), axis=0)\n",
    "        total_precision =np.append(total_precision ,np.array([test_precision]), axis=0)\n",
    "        total_recall =np.append(total_recall ,np.array([test_recall]), axis=0)\n",
    "        total_MCC =np.append(total_MCC ,np.array([test_MCC]), axis=0)\n",
    "           \n",
    "    metrics = {}\n",
    "    metrics['test_accuracy']= total_accuracy\n",
    "    metrics['test_balanced_accuracy']=total_balanced_accuracy\n",
    "    metrics['test_precision']=total_precision\n",
    "    metrics['test_recall']=total_recall\n",
    "    metrics['test_MCC']=total_MCC\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9ba6b-6a79-4439-8ca2-e601dfebf1f8",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c1ef9-d6b3-47ae-907b-aa6db85be680",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', GaussianNB())])\n",
    "\n",
    "space = {\n",
    "'classifier__var_smoothing': hp.quniform('classifier__var_smoothing',0,1,0.0001)}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"/n Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"/n Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"/n Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"/n Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"/n Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'NB_IWSmote_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d834b56-3a4f-491c-85c0-93308f8d5e26",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3a507-8982-4a67-9aa7-acd243788fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= DecisionTreeClassifier()\n",
    "\n",
    "space = {\n",
    "                  'criterion': hp.choice('criterion', ['gini', 'entropy']),\n",
    "                  'max_depth': hp.quniform('max_depth', 1,30,1),\n",
    "                  'max_features': hp.choice('max_features', ['sqrt', 'log2']),\n",
    "                  'min_samples_leaf': hp.uniform('min_samples_leaf',1,5),\n",
    "                  'min_samples_split': hp.uniform('min_samples_split',1,8)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "print('Best parameters: {}'.format(best_param))\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'DT_IWSmote_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4fb3de-2742-45b2-85b4-e47dbbf251db",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380e4dc-b3ed-42e1-a8ee-38389bd0790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', SVC())])\n",
    "\n",
    "space = {\n",
    "                 \n",
    "            'classifier__C': hp.choice('classifier__C', [10, 100, 1000, 10000]),\n",
    "            'classifier__gamma': hp.choice('classifier__gamma', [0.01, 0.001, 0.0001]),\n",
    "            'classifier__kernel': hp.choice('classifier__kernel', ['poly', 'rbf','sigmoid'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'SVC_IWSmote_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e29d52-85b6-45fe-9049-dcfa8b85471f",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd70a2-277f-49d3-8dff-1749788f3544",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[('scaler', RScal),('classifier', KNeighborsClassifier())])\n",
    "\n",
    "space = {\n",
    "                'classifier__metric': hp.choice('classifier__metric', ['euclidean', 'manhattan','minkowski']),\n",
    "                'classifier__n_neighbors': hp.uniform('classifier__n_neighbors', 10,20)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperopt will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'KNN_IWSmote_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4784c-45e5-470a-8985-6702a01f66ea",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c66bca-0046-43e1-b12f-4e075f6d922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= BaggingClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 200)),\n",
    "            'classifier__max_features': hp.quniform('classifier__max_features',10,50,2),\n",
    "            'classifier__bootstrap': hp.choice('classifier__bootstrap', [True, False]),\n",
    "            'classifier__bootstrap_features': hp.choice('classifier__bootstrap_features', [True, False])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'Bagging_IWSmote_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5abf86-156a-4b52-89a2-f5adc9a2bbab",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d07141-17ee-4edb-bf02-bd07efdcc129",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= RandomForestClassifier()\n",
    "\n",
    "space = {\n",
    "            'n_estimators': hp.choice('n_estimators', range(200,10000, 200)),\n",
    "            'max_depth': hp.quniform('max_depth', 1, 30, 2),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            'max_features': hp.uniform('max_features', 0.0001,1),\n",
    "            'min_samples_leaf':hp.uniform('min_samples_leaf',1,5),\n",
    "            'min_samples_split':hp.uniform('min_samples_split',2,6)\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'RF_IWSmote_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347ddec7-ee27-4030-a986-aa5aeea8a418",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3a79ac-1a99-4ac7-84c4-cdf4c79ed58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= xgb.XGBClassifier()\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 30, 2),\n",
    "    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.01, 0.4),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1),\n",
    "    'gamma': hp.uniform('gamma', 0.01, .7),\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 250, 20)),\n",
    "    'min_child_samples': hp.choice('min_child_samples', range(100, 260, 20)),\n",
    "    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.4, 1),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.4, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', range(200,10000, 200))\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = metric(best_param, cv=sss, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'XGBoost_IWSmote_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1465b5-9a77-4fcf-8cad-e1454b613b16",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03250cca-6214-4cd2-a6a8-54736f6d8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= lgb.LGBMClassifier()\n",
    "\n",
    "space = {\n",
    "        'num_leaves': hp.choice('num_leaves',range(20,3000,20)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,30,1)),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0, 1),\n",
    "        'feature_fraction':  hp.uniform('feature_fraction', 0, 1),\n",
    "        'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 0.0005, 0.010),\n",
    "        'lambda_l1': hp.choice('lambda_l1', range(0, 100, 5)),\n",
    "        'lambda_l2': hp.choice('lambda_l2', range(0, 100, 5)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'min_data_in_leaf': hp.choice('min_data_in_leaf', range(200,10000, 100)),\n",
    "        'max_bin': hp.uniform('max_bin', 200, 300),\n",
    "        'min_gain_to_split': hp.uniform('min_gain_to_split', 0,15),\n",
    "        'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss', 'rf'])\n",
    "}\n",
    "\n",
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_param=fmin(fn=resamplingCV, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          trials=trials, # logging\n",
    "          max_evals=100, # maximum number of iterations\n",
    "          rstate=np.random.default_rng(42) # fixing random state for the reproducibility\n",
    "         )\n",
    "execution_time = time.time()-start_time\n",
    "\n",
    "\n",
    "metrics = score_resamplingCV(best_param, X=original_Xtrain, y=original_ytrain)\n",
    "\n",
    "print('-------------------------------')\n",
    "print(\"Average Accuracy: {}\".format(metrics['test_accuracy'].mean()),\n",
    "      \"Average Balanced_Accuracy: {}\".format(metrics['test_balanced_accuracy'].mean()),\n",
    "      \"Average Precision: {}\".format(metrics['test_precision'].mean()),\n",
    "      \"Average Recall: {}\".format(metrics['test_recall'].mean()),\n",
    "      \"Average MCC: {}\".format(metrics['test_MCC'].mean()),\n",
    "      \"Execution time: {}\".format(execution_time))\n",
    "\n",
    "\n",
    "\n",
    "# Adding information into the dataframe\n",
    "Comparingdata_HI = Comparingdata_HI.append({'Classifier' : 'LightGBM_IWSmote_HI',\n",
    "                                      'Accuracy': metrics['test_accuracy'].mean(),\n",
    "                                      'Balanced_Accuracy': metrics['test_balanced_accuracy'].mean(), \n",
    "                                      'Precision': metrics['test_precision'].mean(), \n",
    "                                      'Recall': metrics['test_recall'].mean(),\n",
    "                                      'MCC': metrics['test_MCC'].mean(),\n",
    "                                      'Execution_time': execution_time,\n",
    "                                      'Best_param': best_param}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b207a1-b739-4a52-87a6-53318bfd8294",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859471f-ce0a-4d15-90ab-0658a4898ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table_IH = tabulate(Comparingdata_HI, headers = 'keys', tablefmt = 'html')\n",
    "Table_IH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adee773-1f95-4c6a-a923-7d1229b0a175",
   "metadata": {},
   "source": [
    "# Visualisations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9cc13-f295-4f82-930f-66d1e77cd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualisation_HI = Comparingdata_HI.set_index('Classifier')\n",
    "plt.rcParams['figure.figsize']=[20,30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef8aacc-ab86-483c-955c-94ffffc5ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC_plot_HI = Visualisation_HI.sort_values('MCC', ascending=False).MCC.plot.barh()\n",
    "MCC_plot_HI\n",
    "MCC_plot_HI.figure.savefig(\"MCC_plot_Highly_Imbalanced_Data.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aef42af-9356-4d36-a024-75282b66107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Execution_time_plot_HI = Visualisation_HI.sort_values('Execution_time', ascending=False).Execution_time.plot.barh()\n",
    "Execution_time_plot_HI\n",
    "Execution_time_plot_HI.figure.savefig(\"Execution_time_plot_Imbalanced_Data.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bfa900-7d89-43d0-bbc7-425c5e5c9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall_plot_HI = Visualisation_HI.sort_values('Recall', ascending=False).Recall.plot.barh()\n",
    "Recall_plot_HI\n",
    "Recall_plot_HI.figure.savefig(\"Recall_plot_Imbalanced_Data.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680f353-e59e-49e5-a177-ff96b6eed469",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision_plot_HI = Visualisation_HI.sort_values('Precision', ascending=False).Precision.plot.barh()\n",
    "Precision_plot_HI\n",
    "Precision_plot_HI.figure.savefig(\"Precision_plot_Imbalanced_Data.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaeaa93-816d-489b-bfbc-ee31ff8e31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Balanced_Accuracy_plot_HI = Visualisation_HI.sort_values('Balanced_Accuracy', ascending=False).Balanced_Accuracy.plot.barh()\n",
    "Balanced_Accuracy_plot_HI\n",
    "Balanced_Accuracy_plot_HI.figure.savefig(\"Balanced_Accuracy_plot_Imbalanced_Data.png\",\n",
    "                    format='png',\n",
    "                    dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a7fd7-ca12-4ff2-a610-5d3032864b97",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007bd42-f2bd-4aa8-bebe-b9afb16784a2",
   "metadata": {},
   "source": [
    "### Tables for Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e3d57-e141-4bd9-897b-5f4816f8937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExecutionTime = [['NB', 51.9], ['NB+RUS', 3], ['NB+STL', 4647.9], \n",
    "                  ['NB+IW', 4519.5], \n",
    "                  ['KNN', 1678.1], ['KNN+RUS', 30.3], ['KNN+STL', 6036.1], \n",
    "                  ['KNN+IW', 4967.5],\n",
    "                  ['SVC', 2736.7], ['SVC+RUS', 52.3], ['SVC+STL', 25742.6], \n",
    "                  ['SVC+IW', 22800.1],\n",
    "                  ['DT', 229.7], ['DT+RUS', 2.957], ['DT+STL', 5004.8], \n",
    "                  ['DT+IW', 4859.9],\n",
    "                  ['RF', 1796.8], ['RF+RUS', 32.2], ['RF+STL', 6804.2], \n",
    "                  ['RF+IW', 6805.8],\n",
    "                  ['BEC', 1351.1], ['BEC+RUS', 13.8], ['BEC+STL', 6662.0], \n",
    "                  ['BEC+IW', 6648.0],\n",
    "                  ['XGB', 2348.4], ['XGB+RUS', 12.3], ['XGB+STL', 4794.7], \n",
    "                  ['XGB+IW', 4936.2],\n",
    "                  ['LGBM', 195.9], ['LGBM+RUS', 11.54], ['LGBM+STL', 4558.7], \n",
    "                  ['LGBM+IW', 4566.2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31ebcd-4c64-48c5-9972-cfeb640996e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExecutionTimesTable = pd.DataFrame(\n",
    "    ExecutionTime, columns=['Model', 'Execution time in seconds'])\n",
    "ExecutionTimesTable = ExecutionTimesTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a58c3-7529-447c-b6ad-e05c1ccdd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[11,2]\n",
    "ExecutionTimesViz = ExecutionTimesTable.sort_values('Execution time in seconds', ascending=False).plot.bar(width=0.9, color='green')\n",
    "plt.title('Model Execution Time Plot in Descending Order 1:99')\n",
    "plt.xlabel(None)\n",
    "for label in (ExecutionTimesViz.get_xticklabels() + ExecutionTimesViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "ExecutionTimesViz.figure.savefig('Model_Execution_Time_Plot_1_99.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad84df5-718b-45a4-9c31-0d5597be0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = [['NB', 0.623], ['NB+RUS', 0.614], ['NB+STL', 0.521], \n",
    "                  ['NB+IW', 0.623], \n",
    "                  ['KNN', 0.990], ['KNN+RUS', 0.990], ['KNN+STL', 0.990], \n",
    "                  ['KNN+IW', 0.990],\n",
    "                  ['SVC', 0.990], ['SVC+RUS', 0.990], ['SVC+STL', 0.990], \n",
    "                  ['SVC+IW', 0.990],\n",
    "                  ['DT', 0.977], ['DT+RUS', 0.977], ['DT+STL', 0.977], \n",
    "                  ['DT+IW', 0.977],\n",
    "                  ['RF', 0.990], ['RF+RUS', 0.990], ['RF+STL', 0.990], \n",
    "                  ['RF+IW', 0.990],\n",
    "                  ['BEC', 0.990], ['BEC+RUS', 0.990], ['BEC+STL', 0.990], \n",
    "                  ['BEC+IW', 0.990],\n",
    "                  ['XGB', 0.990], ['XGB+RUS', 0.990], ['XGB+STL', 0.990], \n",
    "                  ['XGB+IW', 0.990],\n",
    "                  ['LGBM', 0.989], ['LGBM+RUS', 0.705], ['LGBM+STL', 0.988], \n",
    "                  ['LGBM+IW', 0.998]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6311388-cc49-418f-8446-fe7ed2446962",
   "metadata": {},
   "outputs": [],
   "source": [
    "AccuracyTable = pd.DataFrame(\n",
    "    Accuracy, columns=['Model', 'Values'])\n",
    "AccuracyTable = AccuracyTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c0235-9b35-475b-8442-fccef56f6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "AccuracyViz = AccuracyTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('Accuracy Values in Descending Order 1:99')\n",
    "plt.xlabel(None)\n",
    "for label in (AccuracyViz.get_xticklabels() + AccuracyViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "AccuracyViz.figure.savefig('Accuracy_Plot_1_99.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c09c49-0b6e-4f43-b9c7-8bd67137fdb3",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e75fd-ee3a-4fdf-a624-2b179d86a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "BalancedAccuracy = [['NB', 0.732], ['NB+RUS', 0.723], ['NB+STL', 0.696], \n",
    "                  ['NB+IW', 0.738], \n",
    "                  ['KNN', 0.500], ['KNN+RUS', 0.500], ['KNN+STL', 0.500], \n",
    "                  ['KNN+IW', 0.500],\n",
    "                  ['SVC', 0.500], ['SVC+RUS', 0.500], ['SVC+STL', 0.500], \n",
    "                  ['SVC+IW', 0.500],\n",
    "                  ['DT', 0.523], ['DT+RUS', 0.521], ['DT+STL', 0.518], \n",
    "                  ['DT+IW', 0.520],\n",
    "                  ['RF', 0.500], ['RF+RUS', 0.500], ['RF+STL', 0.521], \n",
    "                  ['RF+IW', 0.500],\n",
    "                  ['BEC', 0.502], ['BEC+RUS', 0.501], ['BEC+STL', 0.500], \n",
    "                  ['BEC+IW', 0.501],\n",
    "                  ['XGB', 0.500], ['XGB+RUS', 0.500], ['XGB+STL', 0.500], \n",
    "                  ['XGB+IW', 0.500],\n",
    "                  ['LGBM', 0.502], ['LGBM+RUS', 0.719], ['LGBM+STL', 0.509], \n",
    "                  ['LGBM+IW', 0.912]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438df477-2d25-4c0f-a37d-291c44bfdb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "Balanced_AccuracyTable = pd.DataFrame(\n",
    "    BalancedAccuracy, columns=['Model', 'Values'])\n",
    "Balanced_AccuracyTable = Balanced_AccuracyTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1821c-9a00-48d0-83a6-adeaf57b75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "Balanced_AccuracyViz = Balanced_AccuracyTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('Balanced_Accuracy Values in Descending Order 1:99')\n",
    "plt.xlabel(None)\n",
    "for label in (Balanced_AccuracyViz.get_xticklabels() + Balanced_AccuracyViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "Balanced_AccuracyViz.figure.savefig('Balanced__Plot_1_99.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8e834-80de-40de-93a5-ec7391aed4ed",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ecdc85-406b-48fc-97ba-10197a1005c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Precision = [['NB', 0.022], ['NB+RUS', 0.022], ['NB+STL', 0.018], \n",
    "                  ['NB+IW', 0.022], \n",
    "                  ['KNN', 0], ['KNN+RUS', 0], ['KNN+STL', 0], \n",
    "                  ['KNN+IW', 0],\n",
    "                  ['SVC', 0], ['SVC+RUS', 0], ['SVC+STL', 0], \n",
    "                  ['SVC+IW', 0],\n",
    "                  ['DT', 0.042], ['DT+RUS', 0.038], ['DT+STL', 0.036], \n",
    "                  ['DT+IW', 0.041],\n",
    "                  ['RF', 0], ['RF+RUS', 0], ['RF+STL', 0], \n",
    "                  ['RF+IW', 0],\n",
    "                  ['BEC', 0.14], ['BEC+RUS', 0.067], ['BEC+STL', 0.1], \n",
    "                  ['BEC+IW', 0.05],\n",
    "                  ['XGB', 0], ['XGB+RUS', 0], ['XGB+STL', 0], \n",
    "                  ['XGB+IW', 0],\n",
    "                  ['LGBM', 0.044], ['LGBM+RUS', 0.025], ['LGBM+STL', 0.122], \n",
    "                  ['LGBM+IW', 1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fbcba-e9be-403d-aa94-ceecb205c5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PrecisionTable = pd.DataFrame(\n",
    "    Precision, columns=['Model', 'Values'])\n",
    "PrecisionTable = PrecisionTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361632d-32df-4747-bc0b-8efce7949b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "PrecisionViz = PrecisionTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('Precision Values in Descending Order 1:99')\n",
    "plt.xlabel(None)\n",
    "for label in (PrecisionViz.get_xticklabels() + PrecisionViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "PrecisionViz.figure.savefig('Precision_Plot_1_99.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadd53a-ce15-476a-9a73-fc63cba9f735",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb5f0e0-df4f-4eff-9944-8f0a4531e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall = [['NB', 0.844], ['NB+RUS', 0.834], ['NB+STL', 0.875], \n",
    "                  ['NB+IW', 0.853], \n",
    "                  ['KNN', 0], ['KNN+RUS', 0], ['KNN+STL', 0], \n",
    "                  ['KNN+IW', 0],\n",
    "                  ['SVC', 0], ['SVC+RUS', 0], ['SVC+STL', 0], \n",
    "                  ['SVC+IW', 0],\n",
    "                  ['DT', 0.059], ['DT+RUS', 0.056], ['DT+STL', 0.049], \n",
    "                  ['DT+IW', 0.054],\n",
    "                  ['RF', 0], ['RF+RUS', 0], ['RF+STL', 0], \n",
    "                  ['RF+IW', 0],\n",
    "                  ['BEC', 0.005], ['BEC+RUS', 0.002], ['BEC+STL', 0.002], \n",
    "                  ['BEC+IW', 0.002],\n",
    "                  ['XGB', 0], ['XGB+RUS', 0], ['XGB+STL', 0], \n",
    "                  ['XGB+IW', 0],\n",
    "                  ['LGBM', 0.005], ['LGBM+RUS', 0.734], ['LGBM+STL', 0.020], \n",
    "                  ['LGBM+IW', 0.834]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80a2ab-6376-4c05-a82c-464c94e04ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "RecallTable = pd.DataFrame(\n",
    "    Recall, columns=['Model', 'Values'])\n",
    "RecallTable = RecallTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba8abc-23a0-4693-bd4f-3e4d47a3c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "RecallViz = RecallTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('Recall Values in Descending Order 1:99')\n",
    "plt.xlabel(None)\n",
    "for label in (RecallViz.get_xticklabels() + RecallViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "RecallViz.figure.savefig('Recall_Plot_1_99.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891e2206-17cb-49fb-8958-dfa46d89d501",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753ee5b-de23-44de-a41d-aa2a3248465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCC = [['NB', 0.095], ['NB+RUS', 0.092], ['NB+STL', 0.078], \n",
    "                  ['NB+IW', 0.097], \n",
    "                  ['KNN', -0.0002], ['KNN+RUS', -0.0002], ['KNN+STL', -0.0002], \n",
    "                  ['KNN+IW', -0.0002],\n",
    "                  ['SVC', 0], ['SVC+RUS', 0], ['SVC+STL', 0], \n",
    "                  ['SVC+IW', 0],\n",
    "                  ['DT', 0.038], ['DT+RUS', 0.035], ['DT+STL', 0.031], \n",
    "                  ['DT+IW', 0.036],\n",
    "                  ['RF', 0], ['RF+RUS', 0], ['RF+STL', 0], \n",
    "                  ['RF+IW', 0],\n",
    "                  ['BEC', 0.024], ['BEC+RUS', 0.011], ['BEC+STL', 0.014], \n",
    "                  ['BEC+IW', 0.010],\n",
    "                  ['XGB', -0.0004], ['XGB+RUS', -0.0004], ['XGB+STL', -0.0004], \n",
    "                  ['XGB+IW', -0.0004],\n",
    "                  ['LGBM', 0.012], ['LGBM+RUS', 0.095], ['LGBM+STL', 0.044], \n",
    "                  ['LGBM+IW', 0.912]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6dc86d-33d5-46b7-aeec-f1b524ded7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCCTable = pd.DataFrame(\n",
    "    MCC, columns=['Model', 'Values'])\n",
    "MCCTable = MCCTable.set_index('Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389e587-f904-4fd7-9ea7-0963c1c852d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=[10,2]\n",
    "MCCViz = MCCTable.sort_values(\n",
    "    'Values', ascending=False).plot.bar(\n",
    "    width=0.8, color='green')\n",
    "plt.title('MCC Values in Descending Order 1:99')\n",
    "plt.xlabel(None)\n",
    "for label in (MCCViz.get_xticklabels() + MCCViz.get_yticklabels()):\n",
    "    label.set_fontsize(9)\n",
    "MCCViz.figure.savefig('MCC_Plot_1_99.png',\n",
    "                                 format='png',\n",
    "                                 bbox_inches='tight',\n",
    "                                 dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00c838-616c-4da5-b5ad-2c5621d70ec6",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d2c2a-d37d-4b64-b837-371feeb5f26e",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda7c5ab-623f-4e9e-9518-b73a927dcdfb",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807863ff-f437-4a04-bbf9-ca04cb514e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting best parameters of the LGBM+IW\n",
    "Best_param_feature =Comparingdata.loc[2,'Best_param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9f1ae-3eea-42c6-b108-326deecc7868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rerunning the space of LGBM+IW\n",
    "space = {\n",
    "        'num_leaves': hp.choice('num_leaves',range(20,3000,20)),\n",
    "        'max_depth': hp.choice('max_depth', range(1,15,1)),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0, 1),\n",
    "        'feature_fraction':  hp.uniform('feature_fraction', 0, 1),\n",
    "        'min_sum_hessian_in_leaf': hp.uniform('min_sum_hessian_in_leaf', 0.0005, 0.010),\n",
    "        'lambda_l1': hp.choice('lambda_l1', range(0, 100, 5)),\n",
    "        'lambda_l2': hp.choice('lambda_l2', range(0, 100, 5)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "        'min_data_in_leaf': hp.choice('min_data_in_leaf', range(200,10000, 100)),\n",
    "        'max_bin': hp.uniform('max_bin', 200, 300),\n",
    "        'min_gain_to_split': hp.uniform('min_gain_to_split', 0,15),\n",
    "        'n_estimators': hp.choice('n_estimators', range(200,10000, 100)),\n",
    "        'boosting_type': hp.choice('boosting_type', ['gbdt', 'dart', 'goss', 'rf'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd8b343-cfdc-43e8-9384-c1ac80e4a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the parameters\n",
    "model =lgb.LGBMClassifier()\n",
    "test =space_eval(space,Best_param_feature)\n",
    "test['max_bin']=243\n",
    "model.set_params(**test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67436b57-bee4-406b-a47f-7e07bd8e8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "model.fit(original_Xtrain, original_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80471526-3eb4-4f18-abae-2db99175ced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe and plot to show feature importance\n",
    "coefs = pd.DataFrame(\n",
    "   model.feature_importances_,\n",
    "   columns=['Coefficients'], index=imputted_data.loc[:, imputted_data.columns != 'default_ind'].columns\n",
    ")\n",
    "\n",
    "plot_coefs = coefs.sort_values('Coefficients', ascending=True).plot(kind='barh', figsize=(20, 20), color='green', width=0.9)\n",
    "plt.title('Feature Importance Plot for LightGBM Model')\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.subplots_adjust(left=.3)\n",
    "\n",
    "plot_coefs.figure.savefig(\"Feature Importance_good4.png\",\n",
    "                     format = 'png',\n",
    "                     dpi=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
